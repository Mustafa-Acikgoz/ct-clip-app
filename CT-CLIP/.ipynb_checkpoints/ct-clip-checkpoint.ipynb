{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3b0a4dbd-57af-4e3a-a8ca-5a620bd7bc9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated git hooks.\n",
      "Git LFS initialized.\n",
      "\"*.pt\" already supported\n",
      "[main c7d29db] Sync full project to GitHub\n",
      " 3 files changed, 3789 insertions(+), 51 deletions(-)\n",
      " create mode 100644 CT-CLIP/.ipynb_checkpoints/claude3(1)-checkpoint.ipynb\n",
      " create mode 100644 CT-CLIP/claude3(1).ipynb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "To https://github.com/Mustafa-Acikgoz/ct-clip-app.git\n",
      "   e356ad6..c7d29db  main -> main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Branch 'main' set up to track remote branch 'main' from 'github'.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "set -e\n",
    "\n",
    "cd /data/ct-clip-app  # adjust if your working copy is elsewhere\n",
    "\n",
    "# 1. Git identity\n",
    "git config user.name \"Mustafa Ak\"\n",
    "git config user.email \"mustafaxacikgoz@gmail.com\"\n",
    "\n",
    "# 2. Enable LFS (if not already)\n",
    "git lfs install\n",
    "\n",
    "# 3. (Optional) Track large files you care about, e.g., .pt or model artifacts\n",
    "git lfs track \"*.pt\" || true\n",
    "git add .gitattributes || true\n",
    "\n",
    "# 4. Configure GitHub remote with the token (non-interactive auth)\n",
    "git remote remove github || true\n",
    "git remote add github https://$hf_space_backup@github.com/Mustafa-Acikgoz/ct-clip-app.git\n",
    "\n",
    "# 5. Ensure main branch name\n",
    "git branch -M main\n",
    "\n",
    "# 6. Stage everything\n",
    "git add -A\n",
    "\n",
    "# 7. Commit\n",
    "git commit -m \"Sync full project to GitHub\" || echo \"Nothing to commit\"\n",
    "\n",
    "# 8. Push to GitHub\n",
    "git push -u github main\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0391c64c-0657-423b-8deb-3a9d573d2e79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Installing system library libgl1-mesa-glx ---\n",
      "sudo: effective uid is not 0, is /usr/bin/sudo on a file system with the 'nosuid' option set or an NFS file system without root privileges?\n",
      "\n",
      "--- Installing Python packages ---\n",
      "\n",
      "--- Cloning GitHub repositories ---\n",
      "CT-CLIP repository already exists.\n",
      "\n",
      "--- Installing CT-CLIP subpackages in editable mode ---\n",
      "\u001b[33m  DEPRECATION: Legacy editable install of transformer-maskgit==0.0.0 from file:///data/ct-clip-app/CT-CLIP/transformer_maskgit (setup.py develop) is deprecated. pip 25.3 will enforce this behaviour change. A possible replacement is to add a pyproject.toml or enable --use-pep517, and use setuptools >= 64. If the resulting installation is not behaving as expected, try using --config-settings editable_mode=compat. Please consult the setuptools documentation for more information. Discussion can be found at https://github.com/pypa/pip/issues/11457\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "monai 1.5.0 requires torch<2.7.0,>=2.4.1, but you have torch 2.7.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[33m  DEPRECATION: Building 'ImageNetV2_pytorch' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'ImageNetV2_pytorch'. Discussion can be found at https://github.com/pypa/pip/issues/6334\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  DEPRECATION: Legacy editable install of ct-clip==0.1 from file:///data/ct-clip-app/CT-CLIP/CT_CLIP (setup.py develop) is deprecated. pip 25.3 will enforce this behaviour change. A possible replacement is to add a pyproject.toml or enable --use-pep517, and use setuptools >= 64. If the resulting installation is not behaving as expected, try using --config-settings editable_mode=compat. Please consult the setuptools documentation for more information. Discussion can be found at https://github.com/pypa/pip/issues/11457\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "==================================================\n",
      " âœ… Cell 1 complete.\n",
      " ðŸ”´ IMPORTANT: Please restart the kernel now before running Cell 2.\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# ==============================================================================\n",
    "# CELL 1: Environment and Dependencies Setup\n",
    "# ==============================================================================\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# --- 1. Install System Libraries ---\n",
    "print(\"--- Installing system library libgl1-mesa-glx ---\")\n",
    "!sudo apt-get update -qq && sudo apt-get install -y -qq libgl1-mesa-glx\n",
    "\n",
    "# --- 2. Install Python Packages ---\n",
    "print(\"\\n--- Installing Python packages ---\")\n",
    "!pip install -q --upgrade pip\n",
    "!pip install -q torch transformers datasets nibabel monai sentencepiece \\\n",
    "                einops vector-quantize-pytorch ema-pytorch beartype \\\n",
    "                opencv-python-headless protobuf huggingface_hub bitsandbytes pandas\n",
    "\n",
    "# --- 3. Clone CT-CLIP Repository ---\n",
    "print(\"\\n--- Cloning GitHub repositories ---\")\n",
    "if not os.path.isdir(\"CT-CLIP\"):\n",
    "    !git clone https://github.com/ibrahimethemhamamci/CT-CLIP.git -q\n",
    "    print(\"Cloned CT-CLIP.\")\n",
    "else:\n",
    "    print(\"CT-CLIP repository already exists.\")\n",
    "\n",
    "# --- 4. Install CT-CLIP Subpackages ---\n",
    "print(\"\\n--- Installing CT-CLIP subpackages in editable mode ---\")\n",
    "!pip install -q -e CT-CLIP/transformer_maskgit\n",
    "!pip install -q -e CT-CLIP/CT_CLIP\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\" âœ… Cell 1 complete.\")\n",
    "print(\" ðŸ”´ IMPORTANT: Please restart the kernel now before running Cell 2.\")\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e7dbae3-3763-4dd9-96c1-ad676c347807",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Using device: cuda ---\n",
      "\n",
      "--- Loading CT-CLIP Model ---\n",
      "Downloading CT-CLIP v2 weights...\n",
      " âœ… CT-CLIP model loaded and frozen.\n",
      "\n",
      "--- Preparing labels ---\n",
      "Found 18 classes.\n",
      "\n",
      "--- Extracting features for our mini-dataset ---\n",
      "Processing dataset/train/train_18373/train_18373_a/train_18373_a_2.nii.gz...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/miniconda/lib/python3.9/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test all pooling\n",
      "Processing dataset/train/train_19287/train_19287_a/train_19287_a_1.nii.gz...\n",
      "test all pooling\n",
      "Processing dataset/train/train_3282/train_3282_a/train_3282_a_1.nii.gz...\n",
      "test all pooling\n",
      "Processing dataset/train/train_54/train_54_a/train_54_a_2.nii.gz...\n",
      "test all pooling\n",
      "Processing dataset/train/train_12769/train_12769_a/train_12769_a_2.nii.gz...\n",
      "test all pooling\n",
      "Processing dataset/train/train_7066/train_7066_a/train_7066_a_1.nii.gz...\n",
      "test all pooling\n",
      "Processing dataset/train/train_2610/train_2610_a/train_2610_a_2.nii.gz...\n",
      "test all pooling\n",
      "Processing dataset/train/train_9742/train_9742_b/train_9742_b_2.nii.gz...\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# CELL 2: Data Preparation, Feature Extraction (204 Samples), and Saving\n",
    "# ==============================================================================\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import monai.transforms as T\n",
    "from huggingface_hub import hf_hub_download\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "# --- 0. Secure token access (no hardcoded tokens) ---\n",
    "HF_TOKEN = os.environ.get(\"HF_Token\")\n",
    "if not HF_TOKEN:\n",
    "    raise RuntimeError(\"HF_TOKEN missing from Secrets. Set it in Space Settings â†’ Secrets.\")\n",
    "\n",
    "# --- 1. Add cloned repos to Python path ---\n",
    "sys.path.insert(0, os.path.abspath(\"CT-CLIP/transformer_maskgit\"))\n",
    "sys.path.insert(0, os.path.abspath(\"CT-CLIP\"))\n",
    "from transformer_maskgit.MaskGITTransformer import CTViT\n",
    "from ct_clip.ct_clip import CTCLIP\n",
    "\n",
    "# --- 2. Configuration ---\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"--- Using device: {DEVICE} ---\")\n",
    "\n",
    "# --- 3. Load Pre-trained CT-CLIP Model ---\n",
    "print(\"\\n--- Loading CT-CLIP Model ---\")\n",
    "text_encoder_name = \"microsoft/BiomedVLP-CXR-BERT-specialized\"\n",
    "text_tokenizer_clip = AutoTokenizer.from_pretrained(text_encoder_name, trust_remote_code=True)\n",
    "text_encoder = AutoModel.from_pretrained(text_encoder_name, trust_remote_code=True)\n",
    "image_encoder = CTViT(dim=512, codebook_size=8192, image_size=480, patch_size=20,\n",
    "                     temporal_patch_size=10, spatial_depth=4, temporal_depth=4,\n",
    "                     dim_head=32, heads=8)\n",
    "vision_model = CTCLIP(image_encoder=image_encoder, text_encoder=text_encoder,\n",
    "                      dim_image=294912, dim_text=768, dim_latent=512).to(DEVICE)\n",
    "\n",
    "print(\"Downloading CT-CLIP v2 weights...\")\n",
    "ckpt_path = hf_hub_download(\n",
    "    repo_id=\"ibrahimhamamci/CT-RATE\",\n",
    "    repo_type=\"dataset\",\n",
    "    filename=\"models/CT-CLIP-Related/CT-CLIP_v2.pt\",\n",
    "    token=HF_TOKEN,\n",
    ")\n",
    "state = torch.load(ckpt_path, map_location=\"cpu\")\n",
    "vision_model.load_state_dict(state.get(\"state_dict\", state), strict=False)\n",
    "vision_model.eval()\n",
    "for param in vision_model.parameters():\n",
    "    param.requires_grad = False\n",
    "print(\" âœ… CT-CLIP model loaded and frozen.\")\n",
    "\n",
    "# --- 4. Prepare Labels and Data ---\n",
    "print(\"\\n--- Preparing labels ---\")\n",
    "labels_path = hf_hub_download(\n",
    "    repo_id=\"ibrahimhamamci/CT-RATE\",\n",
    "    repo_type=\"dataset\",\n",
    "    filename=\"dataset/multi_abnormality_labels/train_predicted_labels.csv\",\n",
    "    token=HF_TOKEN,\n",
    ")\n",
    "df_labels = pd.read_csv(labels_path)\n",
    "CLASS_NAMES = df_labels.columns[1:].tolist()\n",
    "print(f\"Found {len(CLASS_NAMES)} classes.\")\n",
    "\n",
    "# --- 5. Sample filenames (balanced 204) ---\n",
    "# === Replaced Sample Filenames ===\n",
    "sample_filenames = [\n",
    "    \"train_18373_a_2.nii.gz\",\n",
    "    \"train_19287_a_1.nii.gz\",\n",
    "    \"train_3282_a_1.nii.gz\",\n",
    "    \"train_54_a_2.nii.gz\",\n",
    "    \"train_12769_a_2.nii.gz\",\n",
    "    \"train_7066_a_1.nii.gz\",\n",
    "    \"train_2610_a_2.nii.gz\",\n",
    "    \"train_9742_b_2.nii.gz\",\n",
    "    \"train_11431_a_1.nii.gz\",\n",
    "    \"train_7613_b_1.nii.gz\",\n",
    "    \"train_644_d_1.nii.gz\",\n",
    "    \"train_13314_a_2.nii.gz\",\n",
    "    \"train_8278_b_2.nii.gz\",\n",
    "    \"train_1117_b_1.nii.gz\",\n",
    "    \"train_14817_a_1.nii.gz\",\n",
    "    \"train_7519_a_1.nii.gz\",\n",
    "    \"train_7885_a_1.nii.gz\",\n",
    "    \"train_8907_b_2.nii.gz\",\n",
    "    \"train_10455_a_2.nii.gz\",\n",
    "    \"train_7392_a_2.nii.gz\",\n",
    "    \"train_19972_c_2.nii.gz\",\n",
    "    \"train_16252_a_1.nii.gz\",\n",
    "    \"train_18102_a_1.nii.gz\",\n",
    "    \"train_6022_a_2.nii.gz\",\n",
    "    \"train_15635_a_2.nii.gz\",\n",
    "    \"train_6160_c_2.nii.gz\",\n",
    "    \"train_19885_d_2.nii.gz\",\n",
    "    \"train_14325_a_2.nii.gz\",\n",
    "    \"train_16861_b_1.nii.gz\",\n",
    "    \"train_4514_a_1.nii.gz\",\n",
    "    \"train_5373_a_2.nii.gz\",\n",
    "    \"train_19541_b_2.nii.gz\",\n",
    "    \"train_7730_a_2.nii.gz\",\n",
    "    \"train_19804_a_2.nii.gz\",\n",
    "    \"train_9199_a_1.nii.gz\",\n",
    "    \"train_16924_j_2.nii.gz\",\n",
    "    \"train_17830_a_1.nii.gz\",\n",
    "    \"train_4942_a_3.nii.gz\",\n",
    "    \"train_15885_c_1.nii.gz\",\n",
    "    \"train_19132_b_1.nii.gz\",\n",
    "    \"train_691_a_2.nii.gz\",\n",
    "    \"train_2756_a_2.nii.gz\",\n",
    "    \"train_8730_a_1.nii.gz\",\n",
    "    \"train_4730_a_1.nii.gz\",\n",
    "    \"train_17207_a_1.nii.gz\",\n",
    "    \"train_12678_c_2.nii.gz\",\n",
    "    \"train_14851_a_2.nii.gz\",\n",
    "    \"train_13726_a_1.nii.gz\",\n",
    "    \"train_6426_a_2.nii.gz\",\n",
    "    \"train_12201_a_5.nii.gz\",\n",
    "    \"train_11418_c_2.nii.gz\",\n",
    "    \"train_10043_b_2.nii.gz\",\n",
    "    \"train_2928_a_2.nii.gz\",\n",
    "    \"train_13751_a_1.nii.gz\",\n",
    "    \"train_15353_b_1.nii.gz\",\n",
    "    \"train_13041_a_1.nii.gz\",\n",
    "    \"train_16269_a_2.nii.gz\",\n",
    "    \"train_11081_a_1.nii.gz\",\n",
    "    \"train_16785_a_2.nii.gz\",\n",
    "    \"train_1750_a_1.nii.gz\",\n",
    "    \"train_2184_a_1.nii.gz\",\n",
    "    \"train_6223_a_1.nii.gz\",\n",
    "    \"train_14355_a_2.nii.gz\",\n",
    "    \"train_12009_b_1.nii.gz\",\n",
    "    \"train_3633_a_1.nii.gz\",\n",
    "    \"train_4348_a_1.nii.gz\",\n",
    "    \"train_6007_a_1.nii.gz\",\n",
    "    \"train_11588_a_1.nii.gz\",\n",
    "    \"train_7866_a_2.nii.gz\",\n",
    "    \"train_7188_a_1.nii.gz\",\n",
    "    \"train_17209_a_2.nii.gz\",\n",
    "    \"train_5493_a_2.nii.gz\",\n",
    "    \"train_19456_a_2.nii.gz\",\n",
    "    \"train_13865_a_1.nii.gz\",\n",
    "    \"train_2718_b_1.nii.gz\",\n",
    "    \"train_15034_a_2.nii.gz\",\n",
    "    \"train_18068_b_1.nii.gz\",\n",
    "    \"train_13201_a_2.nii.gz\",\n",
    "    \"train_15876_a_1.nii.gz\",\n",
    "    \"train_1585_b_1.nii.gz\",\n",
    "    \"train_17886_a_2.nii.gz\",\n",
    "    \"train_19144_c_2.nii.gz\",\n",
    "    \"train_15649_a_2.nii.gz\",\n",
    "    \"train_15339_a_1.nii.gz\",\n",
    "    \"train_3881_a_1.nii.gz\",\n",
    "    \"train_14835_a_1.nii.gz\",\n",
    "    \"train_18563_a_2.nii.gz\",\n",
    "    \"train_17418_a_2.nii.gz\",\n",
    "    \"train_14512_a_1.nii.gz\",\n",
    "    \"train_16950_b_1.nii.gz\",\n",
    "    \"train_15940_b_1.nii.gz\",\n",
    "    \"train_7710_a_2.nii.gz\",\n",
    "    \"train_5922_a_2.nii.gz\",\n",
    "    \"train_15900_a_1.nii.gz\",\n",
    "    \"train_14417_a_1.nii.gz\",\n",
    "    \"train_5514_a_2.nii.gz\",\n",
    "    \"train_10744_g_1.nii.gz\",\n",
    "    \"train_1709_b_2.nii.gz\",\n",
    "    \"train_3490_a_2.nii.gz\",\n",
    "    \"train_1270_a_1.nii.gz\",\n",
    "    \"train_14514_b_2.nii.gz\",\n",
    "    \"train_11270_a_1.nii.gz\",\n",
    "    \"train_17564_a_2.nii.gz\",\n",
    "    \"train_3517_a_1.nii.gz\",\n",
    "    \"train_11380_a_1.nii.gz\",\n",
    "    \"train_9064_a_1.nii.gz\",\n",
    "    \"train_5220_a_1.nii.gz\",\n",
    "    \"train_10576_b_2.nii.gz\",\n",
    "    \"train_2158_a_2.nii.gz\",\n",
    "    \"train_2039_d_2.nii.gz\",\n",
    "    \"train_14382_a_2.nii.gz\",\n",
    "    \"train_13737_a_2.nii.gz\",\n",
    "    \"train_13582_a_2.nii.gz\",\n",
    "    \"train_18642_a_2.nii.gz\",\n",
    "    \"train_5049_a_2.nii.gz\",\n",
    "    \"train_19893_a_1.nii.gz\",\n",
    "    \"train_16634_a_1.nii.gz\",\n",
    "    \"train_18373_i_1.nii.gz\",\n",
    "    \"train_11480_c_1.nii.gz\",\n",
    "    \"train_13739_a_4.nii.gz\",\n",
    "    \"train_6052_a_1.nii.gz\",\n",
    "    \"train_15563_a_2.nii.gz\",\n",
    "    \"train_14441_b_1.nii.gz\",\n",
    "    \"train_11753_a_1.nii.gz\",\n",
    "    \"train_17752_a_2.nii.gz\",\n",
    "    \"train_19907_a_2.nii.gz\",\n",
    "    \"train_11562_a_1.nii.gz\",\n",
    "    \"train_11759_a_1.nii.gz\",\n",
    "    \"train_9286_a_1.nii.gz\",\n",
    "    \"train_3664_a_2.nii.gz\",\n",
    "    \"train_14727_a_2.nii.gz\",\n",
    "    \"train_11494_a_1.nii.gz\",\n",
    "    \"train_8103_a_2.nii.gz\",\n",
    "    \"train_3080_a_2.nii.gz\",\n",
    "    \"train_8980_a_1.nii.gz\",\n",
    "    \"train_15545_a_2.nii.gz\",\n",
    "    \"train_10413_a_1.nii.gz\",\n",
    "    \"train_14984_a_2.nii.gz\",\n",
    "    \"train_7314_a_1.nii.gz\",\n",
    "    \"train_6679_a_2.nii.gz\",\n",
    "    \"train_3558_a_2.nii.gz\",\n",
    "    \"train_19260_a_2.nii.gz\",\n",
    "    \"train_9263_a_1.nii.gz\",\n",
    "    \"train_6135_a_1.nii.gz\",\n",
    "    \"train_9028_a_1.nii.gz\",\n",
    "    \"train_14447_a_1.nii.gz\",\n",
    "    \"train_14253_a_1.nii.gz\",\n",
    "    \"train_16753_a_2.nii.gz\",\n",
    "    \"train_9760_a_1.nii.gz\",\n",
    "    \"train_12898_b_1.nii.gz\",\n",
    "    \"train_15973_a_2.nii.gz\",\n",
    "    \"train_7122_a_2.nii.gz\",\n",
    "    \"train_16374_a_2.nii.gz\",\n",
    "    \"train_17089_a_2.nii.gz\",\n",
    "    \"train_16206_a_2.nii.gz\",\n",
    "    \"train_17507_b_1.nii.gz\",\n",
    "    \"train_6846_a_2.nii.gz\",\n",
    "    \"train_366_a_1.nii.gz\",\n",
    "    \"train_2223_a_2.nii.gz\",\n",
    "    \"train_11466_a_1.nii.gz\",\n",
    "    \"train_4242_a_1.nii.gz\",\n",
    "    \"train_1906_a_2.nii.gz\",\n",
    "    \"train_15971_a_2.nii.gz\",\n",
    "    \"train_7429_a_2.nii.gz\",\n",
    "    \"train_5573_a_1.nii.gz\",\n",
    "    \"train_9534_b_2.nii.gz\",\n",
    "    \"train_13203_a_1.nii.gz\",\n",
    "    \"train_10442_a_1.nii.gz\",\n",
    "    \"train_10385_a_2.nii.gz\",\n",
    "    \"train_12856_a_1.nii.gz\",\n",
    "    \"train_10785_a_1.nii.gz\",\n",
    "    \"train_12029_a_1.nii.gz\",\n",
    "    \"train_494_a_1.nii.gz\",\n",
    "    \"train_1292_b_2.nii.gz\",\n",
    "    \"train_794_a_1.nii.gz\",\n",
    "    \"train_7934_a_1.nii.gz\",\n",
    "    \"train_3851_a_2.nii.gz\",\n",
    "    \"train_4174_a_2.nii.gz\",\n",
    "    \"train_11280_a_2.nii.gz\",\n",
    "    \"train_11439_a_2.nii.gz\",\n",
    "    \"train_11158_a_1.nii.gz\",\n",
    "    \"train_11175_a_1.nii.gz\",\n",
    "    \"train_8356_b_1.nii.gz\",\n",
    "    \"train_19657_c_2.nii.gz\",\n",
    "    \"train_18350_a_1.nii.gz\",\n",
    "    \"train_10462_a_2.nii.gz\",\n",
    "    \"train_10635_a_1.nii.gz\",\n",
    "    \"train_19840_a_2.nii.gz\",\n",
    "    \"train_4196_b_1.nii.gz\",\n",
    "    \"train_4272_f_1.nii.gz\",\n",
    "    \"train_5105_e_1.nii.gz\",\n",
    "    \"train_11856_a_1.nii.gz\",\n",
    "    \"train_19427_c_1.nii.gz\",\n",
    "    \"train_13527_a_1.nii.gz\",\n",
    "    \"train_18097_a_2.nii.gz\",\n",
    "    \"train_15026_a_2.nii.gz\",\n",
    "    \"train_870_a_2.nii.gz\",\n",
    "    \"train_7594_a_2.nii.gz\",\n",
    "    \"train_1946_a_1.nii.gz\",\n",
    "    \"train_11336_b_2.nii.gz\",\n",
    "    \"train_16743_a_1.nii.gz\",\n",
    "    \"train_4671_a_2.nii.gz\",\n",
    "    \"train_9384_a_2.nii.gz\",\n",
    "    \"train_1029_a_2.nii.gz\",\n",
    "    \"train_18520_a_1.nii.gz\",\n",
    "    \"train_10051_a_2.nii.gz\",\n",
    "    \"train_12821_a_2.nii.gz\",\n",
    "    \"train_1870_a_2.nii.gz\",\n",
    "    \"train_4836_c_1.nii.gz\",\n",
    "    \"train_9634_a_1.nii.gz\",\n",
    "    \"train_16222_a_2.nii.gz\",\n",
    "    \"train_16609_a_2.nii.gz\",\n",
    "    \"train_10827_a_2.nii.gz\",\n",
    "    \"train_18449_a_1.nii.gz\",\n",
    "    \"train_8125_e_1.nii.gz\",\n",
    "    \"train_4861_a_2.nii.gz\",\n",
    "    \"train_16204_a_2.nii.gz\",\n",
    "    \"train_2880_a_1.nii.gz\",\n",
    "    \"train_2879_a_2.nii.gz\",\n",
    "    \"train_464_a_1.nii.gz\",\n",
    "    \"train_7758_b_2.nii.gz\",\n",
    "    \"train_5227_a_1.nii.gz\",\n",
    "    \"train_599_a_1.nii.gz\",\n",
    "    \"train_16647_a_1.nii.gz\",\n",
    "    \"train_9475_a_2.nii.gz\",\n",
    "    \"train_6496_a_1.nii.gz\",\n",
    "    \"train_9160_a_1.nii.gz\",\n",
    "    \"train_19052_a_1.nii.gz\",\n",
    "    \"train_14662_a_2.nii.gz\",\n",
    "    \"train_17046_a_1.nii.gz\",\n",
    "    \"train_3732_b_2.nii.gz\",\n",
    "    \"train_1854_a_2.nii.gz\",\n",
    "    \"train_15391_a_2.nii.gz\",\n",
    "    \"train_5192_a_2.nii.gz\",\n",
    "    \"train_12614_a_1.nii.gz\",\n",
    "    \"train_1878_a_1.nii.gz\",\n",
    "    \"train_16323_a_1.nii.gz\",\n",
    "    \"train_12304_a_2.nii.gz\",\n",
    "    \"train_8148_a_2.nii.gz\",\n",
    "    \"train_14300_a_1.nii.gz\",\n",
    "    \"train_13033_a_1.nii.gz\",\n",
    "    \"train_1683_a_1.nii.gz\",\n",
    "    \"train_13348_a_2.nii.gz\",\n",
    "    \"train_10834_a_1.nii.gz\",\n",
    "    \"train_15872_a_1.nii.gz\",\n",
    "    \"train_18704_a_2.nii.gz\",\n",
    "    \"train_419_a_2.nii.gz\",\n",
    "    \"train_10775_a_1.nii.gz\",\n",
    "    \"train_19246_a_1.nii.gz\",\n",
    "    \"train_1429_b_1.nii.gz\",\n",
    "    \"train_4300_a_2.nii.gz\",\n",
    "    \"train_14438_a_1.nii.gz\",\n",
    "    \"train_18706_a_2.nii.gz\",\n",
    "    \"train_3634_a_2.nii.gz\",\n",
    "    \"train_15772_a_1.nii.gz\",\n",
    "    \"train_10011_a_1.nii.gz\",\n",
    "    \"train_11977_a_2.nii.gz\",\n",
    "    \"train_13697_a_2.nii.gz\",\n",
    "    \"train_3083_a_1.nii.gz\",\n",
    "    \"train_1897_d_2.nii.gz\",\n",
    "    \"train_4944_a_2.nii.gz\",\n",
    "    \"train_6634_a_1.nii.gz\",\n",
    "    \"train_1162_a_2.nii.gz\",\n",
    "    \"train_10987_a_1.nii.gz\",\n",
    "    \"train_12378_b_2.nii.gz\",\n",
    "    \"train_15294_a_1.nii.gz\",\n",
    "    \"train_9307_a_1.nii.gz\",\n",
    "    \"train_19565_a_1.nii.gz\",\n",
    "    \"train_2282_a_1.nii.gz\",\n",
    "    \"train_3190_a_1.nii.gz\",\n",
    "    \"train_11611_a_1.nii.gz\",\n",
    "    \"train_19687_c_1.nii.gz\",\n",
    "    \"train_6482_a_2.nii.gz\",\n",
    "    \"train_11577_b_2.nii.gz\",\n",
    "    \"train_18467_a_1.nii.gz\",\n",
    "    \"train_7186_a_1.nii.gz\",\n",
    "    \"train_13863_a_2.nii.gz\",\n",
    "    \"train_12252_a_1.nii.gz\",\n",
    "    \"train_6622_a_2.nii.gz\",\n",
    "    \"train_17138_a_1.nii.gz\",\n",
    "    \"train_1104_a_2.nii.gz\",\n",
    "    \"train_7754_d_1.nii.gz\",\n",
    "    \"train_16723_a_1.nii.gz\",\n",
    "    \"train_19020_a_1.nii.gz\",\n",
    "    \"train_11880_d_2.nii.gz\",\n",
    "    \"train_13918_a_1.nii.gz\",\n",
    "    \"train_1713_d_1.nii.gz\",\n",
    "    \"train_14471_a_1.nii.gz\",\n",
    "    \"train_9006_a_1.nii.gz\",\n",
    "    \"train_15553_a_1.nii.gz\",\n",
    "    \"train_11778_a_1.nii.gz\",\n",
    "    \"train_3901_a_1.nii.gz\",\n",
    "    \"train_594_a_1.nii.gz\",\n",
    "    \"train_19704_d_2.nii.gz\",\n",
    "    \"train_4494_a_1.nii.gz\",\n",
    "    \"train_15596_a_2.nii.gz\",\n",
    "    \"train_15080_a_1.nii.gz\",\n",
    "    \"train_19969_a_1.nii.gz\",\n",
    "    \"train_7988_a_1.nii.gz\",\n",
    "    \"train_15283_a_2.nii.gz\",\n",
    "    \"train_3746_a_2.nii.gz\",\n",
    "    \"train_19368_a_1.nii.gz\",\n",
    "    \"train_3963_f_1.nii.gz\",\n",
    "    \"train_11683_b_2.nii.gz\",\n",
    "    \"train_14466_a_2.nii.gz\",\n",
    "    \"train_7376_a_2.nii.gz\",\n",
    "    \"train_4352_a_2.nii.gz\",\n",
    "    \"train_1922_a_1.nii.gz\",\n",
    "    \"train_6967_a_1.nii.gz\",\n",
    "    \"train_13308_a_1.nii.gz\",\n",
    "    \"train_18977_a_2.nii.gz\",\n",
    "    \"train_1526_a_1.nii.gz\",\n",
    "    \"train_1272_a_1.nii.gz\",\n",
    "    \"train_18463_a_2.nii.gz\",\n",
    "    \"train_3843_a_1.nii.gz\",\n",
    "    \"train_16551_a_1.nii.gz\",\n",
    "    \"train_16719_a_2.nii.gz\",\n",
    "    \"train_2212_a_2.nii.gz\",\n",
    "    \"train_9822_a_2.nii.gz\",\n",
    "    \"train_3990_a_1.nii.gz\",\n",
    "    \"train_4791_a_2.nii.gz\",\n",
    "    \"train_2901_c_1.nii.gz\",\n",
    "    \"train_19860_b_2.nii.gz\",\n",
    "    \"train_7835_a_1.nii.gz\",\n",
    "    \"train_12518_a_2.nii.gz\",\n",
    "    \"train_199_a_2.nii.gz\",\n",
    "    \"train_12776_a_1.nii.gz\",\n",
    "    \"train_16798_b_2.nii.gz\",\n",
    "    \"train_14823_b_2.nii.gz\",\n",
    "    \"train_8043_a_2.nii.gz\",\n",
    "    \"train_9414_b_1.nii.gz\",\n",
    "    \"train_6857_a_2.nii.gz\",\n",
    "    \"train_1381_d_2.nii.gz\",\n",
    "    \"train_12218_a_2.nii.gz\",\n",
    "    \"train_7259_b_1.nii.gz\",\n",
    "    \"train_16188_b_2.nii.gz\",\n",
    "    \"train_19346_a_2.nii.gz\",\n",
    "    \"train_4883_a_2.nii.gz\",\n",
    "    \"train_8237_b_1.nii.gz\",\n",
    "    \"train_2123_a_1.nii.gz\",\n",
    "    \"train_16437_a_1.nii.gz\",\n",
    "    \"train_8168_c_1.nii.gz\",\n",
    "    \"train_9835_a_2.nii.gz\",\n",
    "    \"train_7951_a_1.nii.gz\",\n",
    "    \"train_13202_b_1.nii.gz\",\n",
    "    \"train_11593_b_2.nii.gz\",\n",
    "    \"train_13873_a_2.nii.gz\",\n",
    "    \"train_12272_a_1.nii.gz\",\n",
    "    \"train_11969_a_2.nii.gz\",\n",
    "    \"train_4233_a_1.nii.gz\",\n",
    "    \"train_1896_b_2.nii.gz\",\n",
    "    \"train_14993_a_1.nii.gz\",\n",
    "    \"train_3392_a_2.nii.gz\",\n",
    "    \"train_6438_a_1.nii.gz\",\n",
    "    \"train_19151_b_1.nii.gz\",\n",
    "    \"train_16665_a_1.nii.gz\",\n",
    "    \"train_10646_a_2.nii.gz\",\n",
    "    \"train_15588_a_1.nii.gz\",\n",
    "    \"train_2976_a_2.nii.gz\",\n",
    "    \"train_4836_b_1.nii.gz\",\n",
    "    \"train_16862_a_1.nii.gz\",\n",
    "    \"train_19233_a_2.nii.gz\",\n",
    "    \"train_15676_a_1.nii.gz\",\n",
    "    \"train_17417_a_2.nii.gz\",\n",
    "    \"train_17491_a_1.nii.gz\",\n",
    "    \"train_18819_a_1.nii.gz\",\n",
    "    \"train_2379_a_2.nii.gz\",\n",
    "    \"train_14800_a_1.nii.gz\",\n",
    "    \"train_1416_a_1.nii.gz\",\n",
    "    \"train_17679_a_1.nii.gz\",\n",
    "    \"train_10626_a_2.nii.gz\",\n",
    "    \"train_16220_b_1.nii.gz\",\n",
    "    \"train_10084_a_2.nii.gz\",\n",
    "    \"train_14244_a_1.nii.gz\",\n",
    "    \"train_19717_a_2.nii.gz\",\n",
    "    \"train_14480_a_2.nii.gz\",\n",
    "    \"train_15350_a_1.nii.gz\",\n",
    "    \"train_1468_b_2.nii.gz\",\n",
    "    \"train_8538_a_1.nii.gz\",\n",
    "    \"train_16925_a_2.nii.gz\",\n",
    "    \"train_17652_a_2.nii.gz\",\n",
    "    \"train_5509_a_1.nii.gz\",\n",
    "    \"train_16436_a_2.nii.gz\",\n",
    "    \"train_8567_c_2.nii.gz\",\n",
    "    \"train_7063_a_2.nii.gz\",\n",
    "    \"train_18393_a_2.nii.gz\",\n",
    "    \"train_13527_b_2.nii.gz\",\n",
    "    \"train_3053_a_1.nii.gz\",\n",
    "    \"train_17822_a_1.nii.gz\",\n",
    "    \"train_8200_a_1.nii.gz\",\n",
    "    \"train_8740_b_1.nii.gz\",\n",
    "    \"train_17903_a_2.nii.gz\",\n",
    "    \"train_905_a_2.nii.gz\",\n",
    "    \"train_14520_a_1.nii.gz\",\n",
    "    \"train_17645_a_2.nii.gz\",\n",
    "    \"train_9314_b_2.nii.gz\",\n",
    "    \"train_1748_a_2.nii.gz\",\n",
    "    \"train_11319_a_1.nii.gz\",\n",
    "    \"train_13988_a_1.nii.gz\",\n",
    "    \"train_18032_a_2.nii.gz\",\n",
    "    \"train_5634_e_2.nii.gz\",\n",
    "    \"train_2448_a_2.nii.gz\",\n",
    "    \"train_19793_a_2.nii.gz\",\n",
    "    \"train_1896_b_1.nii.gz\",\n",
    "    \"train_5381_a_2.nii.gz\",\n",
    "    \"train_1017_a_2.nii.gz\",\n",
    "    \"train_12329_a_2.nii.gz\",\n",
    "    \"train_12870_a_1.nii.gz\",\n",
    "    \"train_12877_b_2.nii.gz\",\n",
    "    \"train_7946_a_1.nii.gz\",\n",
    "    \"train_11792_a_2.nii.gz\",\n",
    "    \"train_6128_a_2.nii.gz\",\n",
    "    \"train_6367_a_2.nii.gz\",\n",
    "    \"train_7428_a_2.nii.gz\",\n",
    "    \"train_8306_a_2.nii.gz\",\n",
    "    \"train_17197_c_2.nii.gz\",\n",
    "    \"train_14428_a_2.nii.gz\",\n",
    "    \"train_17245_a_1.nii.gz\",\n",
    "    \"train_12362_a_1.nii.gz\",\n",
    "    \"train_15106_a_2.nii.gz\",\n",
    "    \"train_17988_a_1.nii.gz\",\n",
    "    \"train_8841_a_1.nii.gz\",\n",
    "    \"train_3233_b_1.nii.gz\",\n",
    "    \"train_5468_a_1.nii.gz\",\n",
    "    \"train_8957_a_1.nii.gz\",\n",
    "    \"train_19657_a_2.nii.gz\",\n",
    "    \"train_7666_a_2.nii.gz\",\n",
    "    \"train_19687_a_1.nii.gz\",\n",
    "    \"train_15554_a_1.nii.gz\",\n",
    "    \"train_2926_a_1.nii.gz\",\n",
    "    \"train_8199_a_2.nii.gz\",\n",
    "    \"train_17488_a_2.nii.gz\",\n",
    "    \"train_1041_b_2.nii.gz\",\n",
    "    \"train_16624_a_2.nii.gz\",\n",
    "    \"train_11113_a_1.nii.gz\",\n",
    "    \"train_2077_a_2.nii.gz\",\n",
    "    \"train_17872_a_2.nii.gz\",\n",
    "    \"train_2407_a_1.nii.gz\",\n",
    "    \"train_1995_a_1.nii.gz\",\n",
    "    \"train_17649_a_1.nii.gz\",\n",
    "    \"train_12545_a_2.nii.gz\",\n",
    "    \"train_9166_a_1.nii.gz\",\n",
    "    \"train_19330_a_1.nii.gz\",\n",
    "    \"train_19952_a_1.nii.gz\",\n",
    "    \"train_10897_a_2.nii.gz\",\n",
    "    \"train_8617_a_1.nii.gz\",\n",
    "    \"train_3587_a_1.nii.gz\",\n",
    "    \"train_150_a_1.nii.gz\",\n",
    "    \"train_2565_a_2.nii.gz\",\n",
    "    \"train_17714_a_2.nii.gz\",\n",
    "    \"train_5469_b_2.nii.gz\",\n",
    "    \"train_10979_a_1.nii.gz\",\n",
    "    \"train_16296_a_1.nii.gz\",\n",
    "    \"train_7252_a_1.nii.gz\",\n",
    "    \"train_2826_a_1.nii.gz\",\n",
    "    \"train_11401_a_6.nii.gz\",\n",
    "    \"train_13751_a_2.nii.gz\",\n",
    "    \"train_5860_a_1.nii.gz\",\n",
    "    \"train_15288_a_2.nii.gz\",\n",
    "    \"train_5367_a_2.nii.gz\",\n",
    "    \"train_14154_d_3.nii.gz\",\n",
    "    \"train_17079_b_2.nii.gz\",\n",
    "    \"train_7776_a_1.nii.gz\",\n",
    "    \"train_8334_a_1.nii.gz\",\n",
    "    \"train_19154_a_2.nii.gz\",\n",
    "    \"train_8953_a_2.nii.gz\",\n",
    "    \"train_2057_a_1.nii.gz\",\n",
    "    \"train_13024_c_1.nii.gz\",\n",
    "    \"train_12550_a_1.nii.gz\",\n",
    "    \"train_11597_a_1.nii.gz\",\n",
    "    \"train_14927_a_1.nii.gz\",\n",
    "    \"train_3348_a_1.nii.gz\",\n",
    "    \"train_16761_a_1.nii.gz\",\n",
    "    \"train_5257_a_2.nii.gz\",\n",
    "    \"train_18132_a_1.nii.gz\",\n",
    "    \"train_15200_a_1.nii.gz\",\n",
    "    \"train_942_a_1.nii.gz\",\n",
    "    \"train_13896_b_2.nii.gz\",\n",
    "    \"train_17201_a_1.nii.gz\",\n",
    "    \"train_3047_a_1.nii.gz\",\n",
    "    \"train_9479_a_1.nii.gz\",\n",
    "    \"train_15410_a_1.nii.gz\",\n",
    "    \"train_8391_a_1.nii.gz\",\n",
    "    \"train_10449_a_1.nii.gz\",\n",
    "    \"train_13648_b_2.nii.gz\",\n",
    "    \"train_3064_a_1.nii.gz\",\n",
    "    \"train_12766_a_1.nii.gz\",\n",
    "    \"train_2573_a_2.nii.gz\",\n",
    "    \"train_2149_a_2.nii.gz\",\n",
    "    \"train_3484_a_1.nii.gz\",\n",
    "    \"train_12588_b_2.nii.gz\",\n",
    "    \"train_9858_a_2.nii.gz\",\n",
    "    \"train_15827_a_2.nii.gz\",\n",
    "    \"train_5150_a_1.nii.gz\",\n",
    "    \"train_359_c_1.nii.gz\",\n",
    "    \"train_19838_a_2.nii.gz\",\n",
    "    \"train_18689_a_2.nii.gz\",\n",
    "    \"train_13429_a_1.nii.gz\",\n",
    "    \"train_2186_a_1.nii.gz\",\n",
    "    \"train_8415_a_1.nii.gz\",\n",
    "    \"train_14443_b_2.nii.gz\",\n",
    "    \"train_4510_a_1.nii.gz\",\n",
    "    \"train_6165_b_2.nii.gz\",\n",
    "    \"train_10389_a_2.nii.gz\",\n",
    "    \"train_10507_a_1.nii.gz\",\n",
    "    \"train_12927_a_1.nii.gz\",\n",
    "    \"train_7045_a_1.nii.gz\",\n",
    "    \"train_9377_b_2.nii.gz\",\n",
    "    \"train_19888_a_2.nii.gz\",\n",
    "    \"train_15285_c_1.nii.gz\",\n",
    "    \"train_14993_d_1.nii.gz\",\n",
    "    \"train_2465_a_2.nii.gz\",\n",
    "    \"train_5379_a_2.nii.gz\",\n",
    "    \"train_3900_a_2.nii.gz\",\n",
    "    \"train_9226_a_2.nii.gz\",\n",
    "    \"train_16677_a_2.nii.gz\",\n",
    "    \"train_8065_d_1.nii.gz\",\n",
    "    \"train_8169_b_2.nii.gz\",\n",
    "    \"train_11352_a_1.nii.gz\",\n",
    "    \"train_16937_a_2.nii.gz\",\n",
    "    \"train_12243_a_1.nii.gz\",\n",
    "    \"train_16124_a_1.nii.gz\",\n",
    "    \"train_19428_b_2.nii.gz\",\n",
    "    \"train_16309_a_1.nii.gz\",\n",
    "    \"train_8643_a_2.nii.gz\",\n",
    "    \"train_112_a_2.nii.gz\",\n",
    "    \"train_4172_a_2.nii.gz\",\n",
    "    \"train_15646_a_2.nii.gz\",\n",
    "    \"train_12463_a_1.nii.gz\",\n",
    "    \"train_1786_e_2.nii.gz\",\n",
    "    \"train_1636_a_1.nii.gz\",\n",
    "    \"train_14698_c_2.nii.gz\",\n",
    "    \"train_18655_a_1.nii.gz\",\n",
    "    \"train_12365_a_1.nii.gz\",\n",
    "    \"train_19518_a_2.nii.gz\",\n",
    "    \"train_8550_b_2.nii.gz\",\n",
    "    \"train_4111_a_2.nii.gz\",\n",
    "    \"train_6377_e_2.nii.gz\",\n",
    "    \"train_15764_a_1.nii.gz\",\n",
    "    \"train_18751_a_1.nii.gz\",\n",
    "    \"train_182_b_2.nii.gz\",\n",
    "    \"train_1276_a_1.nii.gz\",\n",
    "    \"train_12375_b_1.nii.gz\",\n",
    "    \"train_2232_a_1.nii.gz\",\n",
    "    \"train_16550_b_1.nii.gz\",\n",
    "    \"train_17944_d_2.nii.gz\",\n",
    "    \"train_11908_b_1.nii.gz\",\n",
    "    \"train_17747_c_1.nii.gz\",\n",
    "    \"train_12791_a_2.nii.gz\",\n",
    "    \"train_17736_a_2.nii.gz\",\n",
    "    \"train_13795_a_1.nii.gz\",\n",
    "    \"train_16676_a_1.nii.gz\",\n",
    "    \"train_8987_g_1.nii.gz\",\n",
    "    \"train_3684_a_2.nii.gz\",\n",
    "    \"train_13562_b_1.nii.gz\",\n",
    "    \"train_15013_b_1.nii.gz\",\n",
    "    \"train_4699_a_2.nii.gz\",\n",
    "    \"train_15245_a_1.nii.gz\",\n",
    "    \"train_4636_a_1.nii.gz\",\n",
    "    \"train_10384_a_2.nii.gz\",\n",
    "    \"train_8062_a_2.nii.gz\",\n",
    "    \"train_5385_a_1.nii.gz\",\n",
    "    \"train_7108_a_2.nii.gz\",\n",
    "    \"train_10147_a_1.nii.gz\",\n",
    "    \"train_872_a_2.nii.gz\",\n",
    "    \"train_16724_b_2.nii.gz\",\n",
    "    \"train_13903_b_2.nii.gz\",\n",
    "    \"train_7064_a_1.nii.gz\",\n",
    "    \"train_6836_a_2.nii.gz\",\n",
    "    \"train_16196_a_2.nii.gz\",\n",
    "    \"train_14895_a_2.nii.gz\",\n",
    "    \"train_5347_a_2.nii.gz\",\n",
    "    \"train_4634_a_1.nii.gz\",\n",
    "    \"train_10983_b_1.nii.gz\",\n",
    "    \"train_3168_a_2.nii.gz\",\n",
    "    \"train_954_c_2.nii.gz\",\n",
    "    \"train_9167_a_1.nii.gz\",\n",
    "    \"train_17883_a_1.nii.gz\",\n",
    "    \"train_3310_a_2.nii.gz\",\n",
    "    \"train_11324_a_1.nii.gz\",\n",
    "    \"train_13606_a_2.nii.gz\",\n",
    "    \"train_7474_a_2.nii.gz\",\n",
    "    \"train_5928_a_1.nii.gz\",\n",
    "    \"train_4632_a_2.nii.gz\",\n",
    "    \"train_17610_a_1.nii.gz\",\n",
    "    \"train_11608_a_5.nii.gz\",\n",
    "    \"train_3899_a_2.nii.gz\",\n",
    "    \"train_17927_a_2.nii.gz\",\n",
    "    \"train_19920_a_2.nii.gz\",\n",
    "    \"train_10089_a_2.nii.gz\",\n",
    "    \"train_5275_a_2.nii.gz\",\n",
    "    \"train_8748_a_1.nii.gz\",\n",
    "    \"train_19505_a_2.nii.gz\",\n",
    "    \"train_7735_a_2.nii.gz\",\n",
    "    \"train_5567_a_1.nii.gz\",\n",
    "    \"train_12094_a_1.nii.gz\",\n",
    "    \"train_7701_a_2.nii.gz\",\n",
    "    \"train_10094_b_1.nii.gz\",\n",
    "    \"train_8031_a_1.nii.gz\",\n",
    "    \"train_17470_a_2.nii.gz\",\n",
    "    \"train_16566_c_2.nii.gz\",\n",
    "    \"train_16972_a_1.nii.gz\",\n",
    "    \"train_3712_a_2.nii.gz\",\n",
    "    \"train_17867_a_1.nii.gz\",\n",
    "    \"train_6211_a_2.nii.gz\",\n",
    "    \"train_16834_a_2.nii.gz\",\n",
    "    \"train_3176_a_2.nii.gz\",\n",
    "    \"train_15286_a_1.nii.gz\",\n",
    "    \"train_9899_a_2.nii.gz\",\n",
    "    \"train_8168_a_2.nii.gz\",\n",
    "    \"train_13874_a_2.nii.gz\",\n",
    "    \"train_848_h_1.nii.gz\",\n",
    "    \"train_19526_a_2.nii.gz\",\n",
    "    \"train_1162_a_1.nii.gz\",\n",
    "    \"train_12201_b_2.nii.gz\",\n",
    "    \"train_11863_a_1.nii.gz\",\n",
    "    \"train_7214_e_2.nii.gz\",\n",
    "    \"train_3821_a_5.nii.gz\",\n",
    "    \"train_19669_a_2.nii.gz\",\n",
    "    \"train_3771_a_1.nii.gz\",\n",
    "    \"train_17097_a_4.nii.gz\",\n",
    "    \"train_1948_a_1.nii.gz\",\n",
    "    \"train_5238_a_1.nii.gz\",\n",
    "    \"train_3251_a_1.nii.gz\",\n",
    "    \"train_2364_a_2.nii.gz\",\n",
    "    \"train_6791_a_1.nii.gz\",\n",
    "    \"train_1132_a_2.nii.gz\",\n",
    "    \"train_2658_a_2.nii.gz\",\n",
    "    \"train_3863_b_1.nii.gz\",\n",
    "    \"train_12402_a_1.nii.gz\",\n",
    "    \"train_7006_b_2.nii.gz\",\n",
    "    \"train_18561_a_2.nii.gz\",\n",
    "    \"train_2534_a_1.nii.gz\",\n",
    "    \"train_12684_a_1.nii.gz\",\n",
    "    \"train_1742_b_1.nii.gz\",\n",
    "    \"train_6829_a_2.nii.gz\",\n",
    "    \"train_12543_a_2.nii.gz\",\n",
    "    \"train_15604_a_2.nii.gz\",\n",
    "    \"train_8936_a_2.nii.gz\",\n",
    "    \"train_17413_a_1.nii.gz\",\n",
    "    \"train_13416_a_1.nii.gz\",\n",
    "    \"train_19971_a_1.nii.gz\",\n",
    "    \"train_18744_a_1.nii.gz\",\n",
    "    \"train_8080_b_1.nii.gz\",\n",
    "    \"train_13785_a_1.nii.gz\",\n",
    "    \"train_227_a_2.nii.gz\",\n",
    "    \"train_3010_a_1.nii.gz\",\n",
    "    \"train_12428_a_1.nii.gz\",\n",
    "    \"train_18252_a_1.nii.gz\",\n",
    "    \"train_15178_a_2.nii.gz\",\n",
    "    \"train_12345_a_1.nii.gz\",\n",
    "    \"train_7171_a_1.nii.gz\",\n",
    "    \"train_17912_a_1.nii.gz\",\n",
    "    \"train_17322_b_1.nii.gz\",\n",
    "    \"train_13339_a_1.nii.gz\",\n",
    "    \"train_17619_e_1.nii.gz\",\n",
    "    \"train_11140_a_2.nii.gz\",\n",
    "    \"train_13436_e_2.nii.gz\",\n",
    "    \"train_7578_b_1.nii.gz\",\n",
    "    \"train_3326_b_1.nii.gz\",\n",
    "    \"train_14959_a_2.nii.gz\",\n",
    "    \"train_9113_j_1.nii.gz\",\n",
    "    \"train_5463_a_1.nii.gz\",\n",
    "    \"train_10503_a_1.nii.gz\",\n",
    "    \"train_8867_a_2.nii.gz\",\n",
    "    \"train_3338_a_1.nii.gz\",\n",
    "    \"train_12060_a_2.nii.gz\",\n",
    "    \"train_13354_a_1.nii.gz\",\n",
    "    \"train_4754_a_1.nii.gz\",\n",
    "    \"train_4197_a_1.nii.gz\",\n",
    "    \"train_8483_a_2.nii.gz\",\n",
    "    \"train_12573_a_5.nii.gz\",\n",
    "    \"train_1180_a_2.nii.gz\",\n",
    "    \"train_9833_a_1.nii.gz\",\n",
    "    \"train_12524_a_1.nii.gz\",\n",
    "    \"train_15361_a_1.nii.gz\",\n",
    "    \"train_19726_a_2.nii.gz\",\n",
    "    \"train_17968_a_1.nii.gz\",\n",
    "    \"train_19597_a_2.nii.gz\",\n",
    "    \"train_5771_a_1.nii.gz\",\n",
    "    \"train_2149_a_1.nii.gz\",\n",
    "    \"train_3886_a_1.nii.gz\",\n",
    "    \"train_7719_b_1.nii.gz\",\n",
    "    \"train_2269_a_2.nii.gz\",\n",
    "    \"train_5424_a_1.nii.gz\",\n",
    "    \"train_2874_a_2.nii.gz\",\n",
    "    \"train_13760_a_2.nii.gz\",\n",
    "    \"train_19421_a_1.nii.gz\",\n",
    "    \"train_1689_b_1.nii.gz\",\n",
    "    \"train_17258_a_1.nii.gz\",\n",
    "    \"train_12425_b_2.nii.gz\",\n",
    "    \"train_14868_a_2.nii.gz\",\n",
    "    \"train_4266_b_1.nii.gz\",\n",
    "    \"train_1348_f_1.nii.gz\",\n",
    "    \"train_17802_a_2.nii.gz\",\n",
    "    \"train_13576_a_1.nii.gz\",\n",
    "    \"train_4537_b_1.nii.gz\",\n",
    "    \"train_1462_b_2.nii.gz\",\n",
    "    \"train_3675_c_1.nii.gz\",\n",
    "    \"train_12778_c_2.nii.gz\",\n",
    "    \"train_11001_b_2.nii.gz\",\n",
    "    \"train_5378_a_1.nii.gz\",\n",
    "    \"train_6729_a_1.nii.gz\",\n",
    "    \"train_10267_a_2.nii.gz\",\n",
    "    \"train_1976_a_1.nii.gz\",\n",
    "    \"train_4394_a_1.nii.gz\",\n",
    "    \"train_19256_a_1.nii.gz\",\n",
    "    \"train_2429_a_1.nii.gz\",\n",
    "    \"train_11267_a_2.nii.gz\",\n",
    "    \"train_11896_a_1.nii.gz\",\n",
    "    \"train_8654_a_2.nii.gz\",\n",
    "    \"train_3863_a_1.nii.gz\",\n",
    "    \"train_12000_a_1.nii.gz\",\n",
    "    \"train_7354_a_1.nii.gz\",\n",
    "    \"train_7874_a_1.nii.gz\",\n",
    "    \"train_12287_a_1.nii.gz\",\n",
    "    \"train_5098_a_1.nii.gz\",\n",
    "    \"train_12811_a_1.nii.gz\",\n",
    "    \"train_15236_a_1.nii.gz\",\n",
    "    \"train_18452_c_1.nii.gz\",\n",
    "    \"train_8075_a_1.nii.gz\",\n",
    "    \"train_8344_a_1.nii.gz\",\n",
    "    \"train_14010_a_1.nii.gz\",\n",
    "    \"train_8396_a_1.nii.gz\",\n",
    "    \"train_9831_a_1.nii.gz\",\n",
    "    \"train_488_a_1.nii.gz\",\n",
    "    \"train_10097_a_1.nii.gz\",\n",
    "    \"train_14587_a_1.nii.gz\",\n",
    "    \"train_4488_a_1.nii.gz\",\n",
    "    \"train_12928_a_1.nii.gz\",\n",
    "    \"train_9611_a_1.nii.gz\",\n",
    "    \"train_16841_a_1.nii.gz\",\n",
    "    \"train_17729_a_2.nii.gz\",\n",
    "    \"train_5410_a_2.nii.gz\",\n",
    "    \"train_389_a_2.nii.gz\",\n",
    "    \"train_6162_a_2.nii.gz\",\n",
    "    \"train_19974_a_1.nii.gz\",\n",
    "    \"train_16207_a_2.nii.gz\",\n",
    "    \"train_11585_a_2.nii.gz\",\n",
    "    \"train_6765_a_1.nii.gz\",\n",
    "    \"train_12315_a_1.nii.gz\",\n",
    "    \"train_5972_a_2.nii.gz\",\n",
    "    \"train_14075_a_1.nii.gz\",\n",
    "    \"train_7080_a_2.nii.gz\",\n",
    "    \"train_17867_a_3.nii.gz\",\n",
    "    \"train_12972_a_2.nii.gz\",\n",
    "    \"train_11755_a_1.nii.gz\",\n",
    "    \"train_11885_a_1.nii.gz\",\n",
    "    \"train_1458_a_1.nii.gz\",\n",
    "    \"train_9407_b_2.nii.gz\",\n",
    "    \"train_18439_a_1.nii.gz\",\n",
    "    \"train_7412_a_2.nii.gz\",\n",
    "    \"train_9455_b_1.nii.gz\",\n",
    "    \"train_13595_a_2.nii.gz\",\n",
    "    \"train_4061_a_2.nii.gz\",\n",
    "    \"train_3510_a_2.nii.gz\",\n",
    "    \"train_10666_a_2.nii.gz\",\n",
    "    \"train_8006_a_1.nii.gz\",\n",
    "    \"train_19301_a_1.nii.gz\",\n",
    "    \"train_18458_a_2.nii.gz\",\n",
    "    \"train_16717_a_1.nii.gz\",\n",
    "    \"train_16179_a_1.nii.gz\",\n",
    "    \"train_9593_a_1.nii.gz\",\n",
    "    \"train_7170_a_1.nii.gz\",\n",
    "    \"train_11356_a_2.nii.gz\",\n",
    "    \"train_5243_a_1.nii.gz\",\n",
    "    \"train_3433_a_1.nii.gz\",\n",
    "    \"train_2640_a_2.nii.gz\",\n",
    "    \"train_11811_a_1.nii.gz\",\n",
    "    \"train_4969_a_1.nii.gz\",\n",
    "    \"train_15372_a_1.nii.gz\",\n",
    "    \"train_7592_c_2.nii.gz\",\n",
    "    \"train_10890_a_2.nii.gz\",\n",
    "    \"train_7115_a_2.nii.gz\",\n",
    "    \"train_6394_a_1.nii.gz\",\n",
    "    \"train_3294_a_2.nii.gz\",\n",
    "    \"train_14994_a_1.nii.gz\",\n",
    "    \"train_18325_a_2.nii.gz\",\n",
    "    \"train_17344_a_2.nii.gz\",\n",
    "    \"train_7584_c_2.nii.gz\",\n",
    "    \"train_11119_b_1.nii.gz\",\n",
    "    \"train_9542_a_2.nii.gz\",\n",
    "    \"train_13437_c_2.nii.gz\",\n",
    "    \"train_4154_a_2.nii.gz\",\n",
    "    \"train_12923_b_2.nii.gz\",\n",
    "    \"train_11966_a_1.nii.gz\",\n",
    "    \"train_9361_a_2.nii.gz\",\n",
    "    \"train_13767_a_2.nii.gz\",\n",
    "    \"train_18454_a_2.nii.gz\",\n",
    "    \"train_16440_b_2.nii.gz\",\n",
    "    \"train_1882_a_1.nii.gz\",\n",
    "    \"train_1004_b_2.nii.gz\",\n",
    "    \"train_13963_a_1.nii.gz\",\n",
    "    \"train_8041_a_2.nii.gz\",\n",
    "    \"train_17190_a_1.nii.gz\",\n",
    "    \"train_3165_a_1.nii.gz\",\n",
    "    \"train_15939_a_1.nii.gz\",\n",
    "    \"train_9668_a_2.nii.gz\",\n",
    "    \"train_6959_a_1.nii.gz\",\n",
    "    \"train_11388_a_1.nii.gz\",\n",
    "    \"train_71_a_2.nii.gz\",\n",
    "    \"train_13297_a_1.nii.gz\",\n",
    "    \"train_16955_a_2.nii.gz\",\n",
    "    \"train_16012_a_1.nii.gz\",\n",
    "    \"train_1754_a_1.nii.gz\",\n",
    "    \"train_8583_a_2.nii.gz\",\n",
    "    \"train_1415_a_2.nii.gz\",\n",
    "    \"train_5557_a_2.nii.gz\",\n",
    "    \"train_2248_a_2.nii.gz\",\n",
    "    \"train_16873_a_1.nii.gz\",\n",
    "    \"train_15143_b_2.nii.gz\",\n",
    "    \"train_10439_a_2.nii.gz\",\n",
    "    \"train_3025_a_2.nii.gz\",\n",
    "    \"train_13812_a_1.nii.gz\",\n",
    "    \"train_4832_a_1.nii.gz\",\n",
    "    \"train_1184_b_1.nii.gz\",\n",
    "    \"train_8063_a_1.nii.gz\",\n",
    "    \"train_8848_a_2.nii.gz\",\n",
    "    \"train_5786_b_2.nii.gz\",\n",
    "    \"train_11152_b_1.nii.gz\",\n",
    "    \"train_2426_a_2.nii.gz\",\n",
    "    \"train_1488_a_2.nii.gz\",\n",
    "    \"train_8782_a_5.nii.gz\",\n",
    "    \"train_9204_a_1.nii.gz\",\n",
    "    \"train_9829_a_3.nii.gz\",\n",
    "    \"train_19350_a_1.nii.gz\",\n",
    "    \"train_15907_a_1.nii.gz\",\n",
    "    \"train_15438_a_1.nii.gz\",\n",
    "    \"train_13955_a_2.nii.gz\",\n",
    "    \"train_7702_b_2.nii.gz\",\n",
    "    \"train_7173_b_1.nii.gz\",\n",
    "    \"train_12337_a_2.nii.gz\",\n",
    "    \"train_19427_b_1.nii.gz\",\n",
    "    \"train_16830_a_2.nii.gz\",\n",
    "    \"train_5404_b_2.nii.gz\",\n",
    "    \"train_14115_a_2.nii.gz\",\n",
    "    \"train_8629_a_2.nii.gz\",\n",
    "    \"train_13188_a_1.nii.gz\",\n",
    "    \"train_19922_a_1.nii.gz\",\n",
    "    \"train_19164_b_2.nii.gz\",\n",
    "    \"train_9997_a_2.nii.gz\",\n",
    "    \"train_15839_a_1.nii.gz\",\n",
    "    \"train_2280_a_2.nii.gz\",\n",
    "    \"train_129_a_2.nii.gz\",\n",
    "    \"train_14199_b_1.nii.gz\",\n",
    "    \"train_3012_a_1.nii.gz\",\n",
    "    \"train_1988_a_1.nii.gz\",\n",
    "    \"train_15822_a_1.nii.gz\",\n",
    "    \"train_16867_a_2.nii.gz\",\n",
    "    \"train_724_a_2.nii.gz\",\n",
    "    \"train_17791_c_2.nii.gz\",\n",
    "    \"train_17429_a_2.nii.gz\",\n",
    "    \"train_11530_b_1.nii.gz\",\n",
    "    \"train_18091_a_2.nii.gz\",\n",
    "    \"train_18284_a_2.nii.gz\",\n",
    "    \"train_4129_a_1.nii.gz\",\n",
    "    \"train_2572_a_1.nii.gz\",\n",
    "    \"train_9789_a_2.nii.gz\",\n",
    "    \"train_4200_a_2.nii.gz\",\n",
    "    \"train_2781_a_1.nii.gz\",\n",
    "    \"train_16810_a_2.nii.gz\",\n",
    "    \"train_5117_c_1.nii.gz\",\n",
    "    \"train_11480_a_1.nii.gz\",\n",
    "    \"train_5832_a_1.nii.gz\",\n",
    "    \"train_10085_a_1.nii.gz\",\n",
    "    \"train_1857_a_1.nii.gz\",\n",
    "    \"train_11762_a_1.nii.gz\",\n",
    "    \"train_1592_a_1.nii.gz\",\n",
    "    \"train_16904_a_2.nii.gz\",\n",
    "    \"train_12332_a_2.nii.gz\",\n",
    "    \"train_12160_c_1.nii.gz\",\n",
    "    \"train_13335_b_2.nii.gz\",\n",
    "    \"train_7239_a_1.nii.gz\",\n",
    "    \"train_18313_b_1.nii.gz\",\n",
    "    \"train_10774_a_1.nii.gz\",\n",
    "    \"train_15328_a_1.nii.gz\",\n",
    "    \"train_8017_a_2.nii.gz\",\n",
    "    \"train_6537_a_1.nii.gz\",\n",
    "    \"train_8695_a_1.nii.gz\",\n",
    "    \"train_12262_a_1.nii.gz\",\n",
    "    \"train_14726_a_1.nii.gz\",\n",
    "    \"train_17300_a_1.nii.gz\",\n",
    "    \"train_12845_a_1.nii.gz\",\n",
    "    \"train_15508_a_2.nii.gz\",\n",
    "    \"train_924_a_2.nii.gz\",\n",
    "    \"train_7079_a_2.nii.gz\",\n",
    "    \"train_5989_a_1.nii.gz\",\n",
    "    \"train_1010_a_2.nii.gz\",\n",
    "    \"train_8045_d_2.nii.gz\",\n",
    "    \"train_1058_a_2.nii.gz\",\n",
    "    \"train_16629_a_1.nii.gz\",\n",
    "    \"train_12017_a_2.nii.gz\",\n",
    "    \"train_19857_a_1.nii.gz\",\n",
    "    \"train_6505_a_1.nii.gz\",\n",
    "    \"train_8871_a_1.nii.gz\",\n",
    "    \"train_12439_a_1.nii.gz\",\n",
    "    \"train_14668_a_1.nii.gz\",\n",
    "    \"train_4854_a_2.nii.gz\",\n",
    "    \"train_6435_a_2.nii.gz\",\n",
    "    \"train_3538_a_1.nii.gz\",\n",
    "    \"train_8818_a_1.nii.gz\",\n",
    "    \"train_10375_a_1.nii.gz\",\n",
    "    \"train_8187_a_2.nii.gz\",\n",
    "    \"train_5320_a_2.nii.gz\",\n",
    "    \"train_18457_a_1.nii.gz\",\n",
    "    \"train_11580_a_2.nii.gz\",\n",
    "    \"train_14055_a_2.nii.gz\",\n",
    "    \"train_10321_f_1.nii.gz\",\n",
    "    \"train_5334_a_1.nii.gz\",\n",
    "    \"train_15523_a_1.nii.gz\",\n",
    "    \"train_16158_a_2.nii.gz\",\n",
    "    \"train_807_a_1.nii.gz\",\n",
    "    \"train_8774_a_2.nii.gz\",\n",
    "    \"train_16164_a_2.nii.gz\",\n",
    "    \"train_18793_b_2.nii.gz\",\n",
    "    \"train_15602_a_1.nii.gz\",\n",
    "    \"train_11626_a_1.nii.gz\",\n",
    "    \"train_19795_a_1.nii.gz\",\n",
    "    \"train_3574_a_2.nii.gz\",\n",
    "    \"train_15230_a_1.nii.gz\",\n",
    "    \"train_19926_a_2.nii.gz\",\n",
    "    \"train_3711_a_2.nii.gz\",\n",
    "    \"train_19306_a_2.nii.gz\",\n",
    "    \"train_15717_a_2.nii.gz\",\n",
    "    \"train_9454_a_2.nii.gz\",\n",
    "    \"train_2085_a_1.nii.gz\",\n",
    "    \"train_8004_a_1.nii.gz\",\n",
    "    \"train_5150_a_2.nii.gz\",\n",
    "    \"train_10575_a_1.nii.gz\",\n",
    "    \"train_1422_c_1.nii.gz\",\n",
    "    \"train_13067_a_3.nii.gz\",\n",
    "    \"train_7540_e_1.nii.gz\",\n",
    "    \"train_3748_b_1.nii.gz\",\n",
    "    \"train_8344_a_2.nii.gz\",\n",
    "    \"train_17732_e_2.nii.gz\",\n",
    "    \"train_7811_b_1.nii.gz\",\n",
    "    \"train_116_a_2.nii.gz\",\n",
    "    \"train_2329_f_1.nii.gz\",\n",
    "    \"train_19103_a_2.nii.gz\",\n",
    "    \"train_8132_b_2.nii.gz\",\n",
    "    \"train_5632_b_2.nii.gz\",\n",
    "    \"train_11656_b_1.nii.gz\",\n",
    "    \"train_7124_a_1.nii.gz\",\n",
    "    \"train_1758_c_1.nii.gz\",\n",
    "    \"train_3934_a_1.nii.gz\",\n",
    "    \"train_727_a_2.nii.gz\",\n",
    "    \"train_15667_a_1.nii.gz\",\n",
    "    \"train_16642_a_2.nii.gz\",\n",
    "    \"train_7975_a_1.nii.gz\",\n",
    "    \"train_2374_a_1.nii.gz\",\n",
    "    \"train_14164_a_2.nii.gz\",\n",
    "    \"train_4561_a_2.nii.gz\",\n",
    "    \"train_8583_a_1.nii.gz\",\n",
    "    \"train_11221_a_2.nii.gz\",\n",
    "    \"train_7033_a_2.nii.gz\",\n",
    "    \"train_1914_a_2.nii.gz\",\n",
    "    \"train_344_d_1.nii.gz\",\n",
    "    \"train_4982_a_3.nii.gz\",\n",
    "    \"train_19519_a_1.nii.gz\",\n",
    "    \"train_3021_a_1.nii.gz\",\n",
    "    \"train_10112_b_1.nii.gz\",\n",
    "    \"train_12095_b_1.nii.gz\",\n",
    "    \"train_12132_a_2.nii.gz\",\n",
    "    \"train_4801_a_1.nii.gz\",\n",
    "    \"train_15128_a_2.nii.gz\",\n",
    "    \"train_18320_a_1.nii.gz\",\n",
    "    \"train_882_a_2.nii.gz\",\n",
    "    \"train_13191_a_1.nii.gz\",\n",
    "    \"train_13638_a_2.nii.gz\",\n",
    "    \"train_12005_a_2.nii.gz\",\n",
    "    \"train_3375_a_2.nii.gz\",\n",
    "    \"train_5963_a_1.nii.gz\",\n",
    "    \"train_12364_a_1.nii.gz\",\n",
    "    \"train_2139_d_1.nii.gz\",\n",
    "    \"train_9110_a_2.nii.gz\",\n",
    "    \"train_2093_a_1.nii.gz\",\n",
    "    \"train_5419_a_2.nii.gz\",\n",
    "    \"train_17942_a_1.nii.gz\",\n",
    "    \"train_2558_a_2.nii.gz\",\n",
    "    \"train_13905_a_2.nii.gz\",\n",
    "    \"train_4089_a_1.nii.gz\",\n",
    "    \"train_2511_a_1.nii.gz\",\n",
    "    \"train_10875_a_2.nii.gz\",\n",
    "    \"train_8773_a_2.nii.gz\",\n",
    "    \"train_6850_a_1.nii.gz\",\n",
    "    \"train_3186_b_1.nii.gz\",\n",
    "    \"train_318_a_1.nii.gz\",\n",
    "    \"train_7798_a_2.nii.gz\",\n",
    "    \"train_11625_a_1.nii.gz\",\n",
    "    \"train_19208_a_1.nii.gz\",\n",
    "    \"train_14481_a_2.nii.gz\",\n",
    "    \"train_4064_a_1.nii.gz\",\n",
    "    \"train_12570_a_2.nii.gz\",\n",
    "    \"train_7359_a_2.nii.gz\",\n",
    "    \"train_15321_a_2.nii.gz\",\n",
    "    \"train_13435_a_2.nii.gz\",\n",
    "    \"train_8271_a_1.nii.gz\",\n",
    "    \"train_5448_a_1.nii.gz\",\n",
    "    \"train_19002_a_1.nii.gz\",\n",
    "    \"train_4169_a_1.nii.gz\"\n",
    "]\n",
    "\n",
    "# --- 6. Preprocessing and Feature Extraction ---\n",
    "def load_and_preprocess_ct(path: str):\n",
    "    transform = T.Compose([\n",
    "        T.LoadImaged(keys=[\"image\"]), T.EnsureChannelFirstd(keys=[\"image\"]),\n",
    "        T.ScaleIntensityRanged(keys=[\"image\"], a_min=-1000, a_max=1000,\n",
    "                               b_min=-1.0, b_max=1.0, clip=True),\n",
    "        T.Resized(keys=[\"image\"], spatial_size=(40, 480, 480),\n",
    "                  mode=\"trilinear\", align_corners=False),\n",
    "        T.ToTensord(keys=[\"image\"]),\n",
    "    ])\n",
    "    data = transform({\"image\": path})\n",
    "    return data[\"image\"].unsqueeze(0).to(DEVICE)\n",
    "\n",
    "def reconstruct_path_from_filename(filename: str) -> str:\n",
    "    parts = filename.replace('.nii.gz', '').split('_')\n",
    "    train_id = parts[1]\n",
    "    scan_id = parts[2]\n",
    "    return f\"dataset/train/train_{train_id}/train_{train_id}_{scan_id}/{filename}\"\n",
    "\n",
    "print(\"\\n--- Extracting features for our mini-dataset ---\")\n",
    "training_data = []\n",
    "for filename in sample_filenames:\n",
    "    try:\n",
    "        full_path = reconstruct_path_from_filename(filename)\n",
    "        print(f\"Processing {full_path}...\")\n",
    "        local_path = hf_hub_download(\n",
    "            repo_id=\"ibrahimhamamci/CT-RATE\",\n",
    "            repo_type=\"dataset\",\n",
    "            filename=full_path,\n",
    "            token=HF_TOKEN,\n",
    "        )\n",
    "        ct_tensor = load_and_preprocess_ct(local_path)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            dummy_text_input = text_tokenizer_clip([\"\"], return_tensors=\"pt\", padding=True).to(DEVICE)\n",
    "            _, image_embedding, _ = vision_model(dummy_text_input, ct_tensor, DEVICE, return_latents=True)\n",
    "\n",
    "        labels_row = df_labels[df_labels['VolumeName'] == filename]\n",
    "        if not labels_row.empty:\n",
    "            label_vector = torch.tensor(labels_row.iloc[0, 1:].values.astype(np.float32)).to(DEVICE)\n",
    "            training_data.append((image_embedding, label_vector))\n",
    "    except Exception as e:\n",
    "        print(f\"Could not process file {filename}. Error: {e}. Skipping.\")\n",
    "\n",
    "print(f\"\\n âœ… Cell 2 complete. Created a mini-dataset with {len(training_data)} samples.\")\n",
    "\n",
    "# === 7. Save extracted features and labels for later reuse ===\n",
    "os.makedirs(\"saved_artifacts\", exist_ok=True)\n",
    "image_embeddings = torch.cat([item[0] for item in training_data], dim=0)  # [N, 512]\n",
    "label_vectors = torch.stack([item[1] for item in training_data], dim=0)   # [N, num_classes]\n",
    "\n",
    "torch.save({\n",
    "    \"image_embeddings\": image_embeddings,\n",
    "    \"label_vectors\": label_vectors,\n",
    "    \"class_names\": CLASS_NAMES,\n",
    "}, \"saved_artifacts/features_labels.pt\")\n",
    "\n",
    "# Save sample filename manifest\n",
    "with open(\"saved_artifacts/sample_filenames.txt\", \"w\") as f:\n",
    "    for name in sample_filenames:\n",
    "        full_path = reconstruct_path_from_filename(name)\n",
    "        f.write(f\"{name}\\t{full_path}\\n\")\n",
    "\n",
    "# Save a human-readable summary\n",
    "summary_rows = []\n",
    "for i, (emb, label) in enumerate(training_data):\n",
    "    summary_rows.append({\n",
    "        \"sample_index\": i,\n",
    "        \"volume_name\": sample_filenames[i],\n",
    "        \"embedding_norm\": emb.norm().item(),\n",
    "        **{f\"class_{j}\": label[j].item() for j in range(label.shape[0])}\n",
    "    })\n",
    "df_summary = pd.DataFrame(summary_rows)\n",
    "df_summary.to_csv(\"saved_artifacts/training_summary.csv\", index=False)\n",
    "\n",
    "print(\"âœ… Saved features+labels, sample list, and summary to `saved_artifacts/`\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d131d040-4464-40c3-91dd-74b55bd88c5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Š Training on 320 samples with 5-fold cross-validation...\n",
      "ðŸ” Starting cross-validation training...\n",
      "\n",
      "ðŸ§ª Fold 1/5\n",
      "  Epoch 10/30 - Loss: 0.5945\n",
      "  Epoch 20/30 - Loss: 0.5883\n",
      "  Epoch 30/30 - Loss: 0.5856\n",
      "\n",
      "ðŸ§ª Fold 2/5\n",
      "  Epoch 10/30 - Loss: 0.5846\n",
      "  Epoch 20/30 - Loss: 0.5817\n",
      "  Epoch 30/30 - Loss: 0.5794\n",
      "\n",
      "ðŸ§ª Fold 3/5\n",
      "  Epoch 10/30 - Loss: 0.5823\n",
      "  Epoch 20/30 - Loss: 0.5796\n",
      "  Epoch 30/30 - Loss: 0.5799\n",
      "\n",
      "ðŸ§ª Fold 4/5\n",
      "  Epoch 10/30 - Loss: 0.5806\n",
      "  Epoch 20/30 - Loss: 0.5789\n",
      "  Epoch 30/30 - Loss: 0.5783\n",
      "\n",
      "ðŸ§ª Fold 5/5\n",
      "  Epoch 10/30 - Loss: 0.5879\n",
      "  Epoch 20/30 - Loss: 0.5862\n",
      "  Epoch 30/30 - Loss: 0.5854\n",
      "\n",
      "ðŸŽ¯ Tuning per-class decision thresholds...\n",
      "  Class Medical material                   : best threshold = 0.20 | F1 = 0.425\n",
      "  Class Arterial wall calcification        : best threshold = 0.10 | F1 = 0.686\n",
      "  Class Cardiomegaly                       : best threshold = 0.25 | F1 = 0.490\n",
      "  Class Pericardial effusion               : best threshold = 0.10 | F1 = 0.329\n",
      "  Class Coronary artery wall calcification : best threshold = 0.40 | F1 = 0.635\n",
      "  Class Hiatal hernia                      : best threshold = 0.10 | F1 = 0.400\n",
      "  Class Lymphadenopathy                    : best threshold = 0.10 | F1 = 0.587\n",
      "  Class Emphysema                          : best threshold = 0.20 | F1 = 0.466\n",
      "  Class Atelectasis                        : best threshold = 0.35 | F1 = 0.614\n",
      "  Class Lung nodule                        : best threshold = 0.10 | F1 = 0.712\n",
      "  Class Lung opacity                       : best threshold = 0.25 | F1 = 0.629\n",
      "  Class Pulmonary fibrotic sequela         : best threshold = 0.10 | F1 = 0.555\n",
      "  Class Pleural effusion                   : best threshold = 0.25 | F1 = 0.489\n",
      "  Class Mosaic attenuation pattern         : best threshold = 0.20 | F1 = 0.333\n",
      "  Class Peribronchial thickening           : best threshold = 0.20 | F1 = 0.389\n",
      "  Class Consolidation                      : best threshold = 0.15 | F1 = 0.444\n",
      "  Class Bronchiectasis                     : best threshold = 0.15 | F1 = 0.272\n",
      "  Class Interlobular septal thickening     : best threshold = 0.15 | F1 = 0.398\n",
      "\n",
      "ðŸ§® Fitting Platt scaling calibrators...\n",
      "\n",
      "âœ… DONE: Classifier trained, thresholds tuned, calibrators saved.\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# IMPROVED CELL 3: Classifier Training + Cross-Val Thresholds + Platt Calibration\n",
    "# ==============================================================================\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "\n",
    "print(f\"ðŸ“Š Training on {len(training_data)} samples with 5-fold cross-validation...\")\n",
    "\n",
    "# --- Prepare inputs ---\n",
    "image_embeddings = torch.cat([item[0] for item in training_data], dim=0)  # [N, D]\n",
    "label_vectors = torch.stack([item[1] for item in training_data], dim=0)   # [N, C]\n",
    "num_classes = label_vectors.shape[1]\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# --- Define classifier with dropout ---\n",
    "classifier_head = nn.Sequential(\n",
    "    nn.Dropout(p=0.3),\n",
    "    nn.Linear(image_embeddings.shape[1], num_classes)\n",
    ").to(DEVICE)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(classifier_head.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "\n",
    "# --- Cross-validation loop ---\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "logits_oof = np.zeros((len(training_data), num_classes))\n",
    "true_labels = label_vectors.cpu().numpy()\n",
    "\n",
    "print(\"ðŸ” Starting cross-validation training...\")\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(image_embeddings)):\n",
    "    print(f\"\\nðŸ§ª Fold {fold + 1}/5\")\n",
    "\n",
    "    classifier_head.train()\n",
    "    for epoch in range(30):\n",
    "        total_loss = 0\n",
    "        for idx in train_idx:\n",
    "            emb = image_embeddings[idx].unsqueeze(0).to(DEVICE)\n",
    "            lbl = label_vectors[idx].to(DEVICE)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            out = classifier_head(emb).squeeze(0)\n",
    "            loss = criterion(out, lbl)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            avg_loss = total_loss / len(train_idx)\n",
    "            print(f\"  Epoch {epoch + 1}/30 - Loss: {avg_loss:.4f}\")\n",
    "\n",
    "    # Validation logits\n",
    "    classifier_head.eval()\n",
    "    with torch.no_grad():\n",
    "        for idx in val_idx:\n",
    "            emb = image_embeddings[idx].unsqueeze(0).to(DEVICE)\n",
    "            logits = classifier_head(emb).squeeze(0)\n",
    "            logits_oof[idx] = logits.cpu().numpy()\n",
    "\n",
    "# --- Threshold tuning ---\n",
    "print(\"\\nðŸŽ¯ Tuning per-class decision thresholds...\")\n",
    "val_probs = torch.sigmoid(torch.tensor(logits_oof)).numpy()\n",
    "best_thresholds = []\n",
    "for c in range(num_classes):\n",
    "    best_f1, best_t = 0, 0.5\n",
    "    for t in np.linspace(0.1, 0.9, 17):\n",
    "        pred = (val_probs[:, c] > t).astype(int)\n",
    "        f1 = f1_score(true_labels[:, c], pred, zero_division=0)\n",
    "        if f1 > best_f1:\n",
    "            best_f1, best_t = f1, t\n",
    "    best_thresholds.append(best_t)\n",
    "    print(f\"  Class {CLASS_NAMES[c]:<35}: best threshold = {best_t:.2f} | F1 = {best_f1:.3f}\")\n",
    "\n",
    "# --- Platt scaling (calibration) ---\n",
    "print(\"\\nðŸ§® Fitting Platt scaling calibrators...\")\n",
    "calibrators = {}\n",
    "calibrated_probs = np.zeros_like(val_probs)\n",
    "\n",
    "for c in range(num_classes):\n",
    "    X = logits_oof[:, c].reshape(-1, 1)\n",
    "    y = true_labels[:, c]\n",
    "    if len(np.unique(y)) < 2:\n",
    "        calibrated_probs[:, c] = val_probs[:, c]\n",
    "        continue\n",
    "    lr = LogisticRegression(solver=\"lbfgs\")\n",
    "    lr.fit(X, y)\n",
    "    calibrated_probs[:, c] = lr.predict_proba(X)[:, 1]\n",
    "    calibrators[c] = lr\n",
    "\n",
    "# --- Save artifacts ---\n",
    "os.makedirs(\"saved_artifacts\", exist_ok=True)\n",
    "torch.save({\n",
    "    \"classifier_state_dict\": classifier_head.state_dict(),\n",
    "    \"thresholds\": best_thresholds,\n",
    "    \"calibrators\": calibrators,\n",
    "    \"class_names\": CLASS_NAMES,\n",
    "}, \"saved_artifacts/classifier_calibrated_and_thresholds.pt\")\n",
    "\n",
    "print(\"\\nâœ… DONE: Classifier trained, thresholds tuned, calibrators saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "803f7c72-79af-45f9-bee0-5cea8f73437e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# CELL 2: Data Preparation, Feature Extraction (1000 Samples from CSV), and Saving\n",
    "# ==============================================================================\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import monai.transforms as T\n",
    "from huggingface_hub import hf_hub_download\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "# --- 0. Secure token access (no hardcoded tokens) ---\n",
    "HF_TOKEN = os.environ.get(\"HF_Token\")\n",
    "if not HF_TOKEN:\n",
    "    raise RuntimeError(\"HF_TOKEN missing from Secrets. Set it in Space Settings â†’ Secrets.\")\n",
    "\n",
    "# --- 1. Add cloned repos to Python path ---\n",
    "sys.path.insert(0, os.path.abspath(\"CT-CLIP/transformer_maskgit\"))\n",
    "sys.path.insert(0, os.path.abspath(\"CT-CLIP\"))\n",
    "from transformer_maskgit.MaskGITTransformer import CTViT\n",
    "from ct_clip.ct_clip import CTCLIP\n",
    "\n",
    "# --- 2. Configuration ---\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"--- Using device: {DEVICE} ---\")\n",
    "\n",
    "# --- 3. Load Pre-trained CT-CLIP Model ---\n",
    "print(\"\\n--- Loading CT-CLIP Model ---\")\n",
    "text_encoder_name = \"microsoft/BiomedVLP-CXR-BERT-specialized\"\n",
    "text_tokenizer_clip = AutoTokenizer.from_pretrained(text_encoder_name, trust_remote_code=True)\n",
    "text_encoder = AutoModel.from_pretrained(text_encoder_name, trust_remote_code=True)\n",
    "image_encoder = CTViT(dim=512, codebook_size=8192, image_size=480, patch_size=20,\n",
    "                     temporal_patch_size=10, spatial_depth=4, temporal_depth=4,\n",
    "                     dim_head=32, heads=8)\n",
    "vision_model = CTCLIP(image_encoder=image_encoder, text_encoder=text_encoder,\n",
    "                      dim_image=294912, dim_text=768, dim_latent=512).to(DEVICE)\n",
    "\n",
    "print(\"Downloading CT-CLIP v2 weights...\")\n",
    "ckpt_path = hf_hub_download(\n",
    "    repo_id=\"ibrahimhamamci/CT-RATE\",\n",
    "    repo_type=\"dataset\",\n",
    "    filename=\"models/CT-CLIP-Related/CT-CLIP_v2.pt\",\n",
    "    token=HF_TOKEN,\n",
    ")\n",
    "state = torch.load(ckpt_path, map_location=\"cpu\")\n",
    "vision_model.load_state_dict(state.get(\"state_dict\", state), strict=False)\n",
    "vision_model.eval()\n",
    "for param in vision_model.parameters():\n",
    "    param.requires_grad = False\n",
    "print(\" âœ… CT-CLIP model loaded and frozen.\")\n",
    "\n",
    "# --- 4. Prepare Labels ---\n",
    "print(\"\\n--- Preparing labels ---\")\n",
    "labels_path = hf_hub_download(\n",
    "    repo_id=\"ibrahimhamamci/CT-RATE\",\n",
    "    repo_type=\"dataset\",\n",
    "    filename=\"dataset/multi_abnormality_labels/train_predicted_labels.csv\",\n",
    "    token=HF_TOKEN,\n",
    ")\n",
    "df_labels = pd.read_csv(labels_path)\n",
    "CLASS_NAMES = df_labels.columns[1:].tolist()\n",
    "print(f\"Found {len(CLASS_NAMES)} classes.\")\n",
    "\n",
    "# --- 5. Load sample filenames from uploaded CSV ---\n",
    "df_samples = pd.read_csv(\"sample_1000_filenames.csv\")\n",
    "sample_filenames = df_samples.iloc[:, 0].tolist()\n",
    "print(f\"Loaded {len(sample_filenames)} filenames from CSV.\")\n",
    "\n",
    "# --- 6. Preprocessing and Feature Extraction ---\n",
    "def load_and_preprocess_ct(path: str):\n",
    "    transform = T.Compose([\n",
    "        T.LoadImaged(keys=[\"image\"]), T.EnsureChannelFirstd(keys=[\"image\"]),\n",
    "        T.ScaleIntensityRanged(keys=[\"image\"], a_min=-1000, a_max=1000,\n",
    "                               b_min=-1.0, b_max=1.0, clip=True),\n",
    "        T.Resized(keys=[\"image\"], spatial_size=(40, 480, 480),\n",
    "                  mode=\"trilinear\", align_corners=False),\n",
    "        T.ToTensord(keys=[\"image\"]),\n",
    "    ])\n",
    "    data = transform({\"image\": path})\n",
    "    return data[\"image\"].unsqueeze(0).to(DEVICE)\n",
    "\n",
    "def reconstruct_path_from_filename(filename: str) -> str:\n",
    "    parts = filename.replace('.nii.gz', '').split('_')\n",
    "    train_id = parts[1]\n",
    "    scan_id = parts[2]\n",
    "    return f\"dataset/train/train_{train_id}/train_{train_id}_{scan_id}/{filename}\"\n",
    "\n",
    "print(\"\\n--- Extracting features for CT scans ---\")\n",
    "training_data = []\n",
    "for filename in sample_filenames:\n",
    "    try:\n",
    "        full_path = reconstruct_path_from_filename(filename)\n",
    "        print(f\"Processing {full_path}...\")\n",
    "        local_path = hf_hub_download(\n",
    "            repo_id=\"ibrahimhamamci/CT-RATE\",\n",
    "            repo_type=\"dataset\",\n",
    "            filename=full_path,\n",
    "            token=HF_TOKEN,\n",
    "        )\n",
    "        ct_tensor = load_and_preprocess_ct(local_path)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            dummy_text_input = text_tokenizer_clip([\"\"], return_tensors=\"pt\", padding=True).to(DEVICE)\n",
    "            _, image_embedding, _ = vision_model(dummy_text_input, ct_tensor, DEVICE, return_latents=True)\n",
    "\n",
    "        labels_row = df_labels[df_labels['VolumeName'] == filename]\n",
    "        if not labels_row.empty:\n",
    "            label_vector = torch.tensor(labels_row.iloc[0, 1:].values.astype(np.float32)).to(DEVICE)\n",
    "            training_data.append((image_embedding, label_vector))\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ Could not process file {filename}. Error: {e}. Skipping.\")\n",
    "\n",
    "print(f\"\\n âœ… Cell 2 complete. Created a dataset with {len(training_data)} samples.\")\n",
    "\n",
    "# --- 7. Save extracted features and labels for later reuse ---\n",
    "os.makedirs(\"saved_artifacts\", exist_ok=True)\n",
    "image_embeddings = torch.cat([item[0] for item in training_data], dim=0)  # [N, 512]\n",
    "label_vectors = torch.stack([item[1] for item in training_data], dim=0)   # [N, num_classes]\n",
    "\n",
    "torch.save({\n",
    "    \"image_embeddings\": image_embeddings,\n",
    "    \"label_vectors\": label_vectors,\n",
    "    \"class_names\": CLASS_NAMES,\n",
    "}, \"saved_artifacts/features_labels.pt\")\n",
    "\n",
    "# Save sample filename manifest\n",
    "with open(\"saved_artifacts/sample_filenames.txt\", \"w\") as f:\n",
    "    for name in sample_filenames:\n",
    "        full_path = reconstruct_path_from_filename(name)\n",
    "        f.write(f\"{name}\\t{full_path}\\n\")\n",
    "\n",
    "# Save a human-readable summary\n",
    "summary_rows = []\n",
    "for i, (emb, label) in enumerate(training_data):\n",
    "    summary_rows.append({\n",
    "        \"sample_index\": i,\n",
    "        \"volume_name\": sample_filenames[i],\n",
    "        \"embedding_norm\": emb.norm().item(),\n",
    "        **{f\"class_{j}\": label[j].item() for j in range(label.shape[0])}\n",
    "    })\n",
    "df_summary = pd.DataFrame(summary_rows)\n",
    "df_summary.to_csv(\"saved_artifacts/training_summary.csv\", index=False)\n",
    "\n",
    "print(\"âœ… Saved features+labels, sample list, and summary to `saved_artifacts/`\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a29e3fec-0ad7-4c43-a167-395e5d73767f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
