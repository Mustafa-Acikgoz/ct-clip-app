{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3b0a4dbd-57af-4e3a-a8ca-5a620bd7bc9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "$ git config user.name \"Mustafa Ak\"\n",
      "=== STDOUT ===\n",
      "<none>\n",
      "=== STDERR ===\n",
      "<none>\n",
      "returncode: 0\n",
      "\n",
      "$ git config user.email \"mustafaxacikgoz@gmail.com\"\n",
      "=== STDOUT ===\n",
      "<none>\n",
      "=== STDERR ===\n",
      "<none>\n",
      "returncode: 0\n",
      "\n",
      "$ git status\n",
      "=== STDOUT ===\n",
      "On branch main\n",
      "Your branch is up to date with 'origin/main'.\n",
      "\n",
      "Changes not staged for commit:\n",
      "  (use \"git add <file>...\" to update what will be committed)\n",
      "  (use \"git restore <file>...\" to discard changes in working directory)\n",
      "\tmodified:   CT-CLIP/CT_CLIP/ct_clip/__pycache__/__init__.cpython-39.pyc\n",
      "\tmodified:   CT-CLIP/CT_CLIP/ct_clip/__pycache__/ct_clip.cpython-39.pyc\n",
      "\tmodified:   CT-CLIP/CT_CLIP/ct_clip/__pycache__/mlm.cpython-39.pyc\n",
      "\tmodified:   CT-CLIP/CT_CLIP/ct_clip/__pycache__/visual_ssl.cpython-39.pyc\n",
      "\tmodified:   CT-CLIP/ct-clip.ipynb\n",
      "\tmodified:   CT-CLIP/transformer_maskgit/transformer_maskgit/__pycache__/MaskGITTransformer.cpython-39.pyc\n",
      "\tmodified:   CT-CLIP/transformer_maskgit/transformer_maskgit/__pycache__/__init__.cpython-39.pyc\n",
      "\tmodified:   CT-CLIP/transformer_maskgit/transformer_maskgit/__pycache__/attention.cpython-39.pyc\n",
      "\tmodified:   CT-CLIP/transformer_maskgit/transformer_maskgit/__pycache__/ctvit.cpython-39.pyc\n",
      "\tmodified:   CT-CLIP/transformer_maskgit/transformer_maskgit/__pycache__/ctvit_trainer.cpython-39.pyc\n",
      "\tmodified:   CT-CLIP/transformer_maskgit/transformer_maskgit/__pycache__/data.cpython-39.pyc\n",
      "\tmodified:   CT-CLIP/transformer_maskgit/transformer_maskgit/__pycache__/optimizer.cpython-39.pyc\n",
      "\tmodified:   CT-CLIP/transformer_maskgit/transformer_maskgit/__pycache__/t5.cpython-39.pyc\n",
      "\tmodified:   CT-CLIP/transformer_maskgit/transformer_maskgit/__pycache__/videotextdataset.cpython-39.pyc\n",
      "\n",
      "Untracked files:\n",
      "  (use \"git add <file>...\" to include in what will be committed)\n",
      "\tCT-CLIP/.ipynb_checkpoints/\n",
      "\n",
      "no changes added to commit (use \"git add\" and/or \"git commit -a\")\n",
      "=== STDERR ===\n",
      "<none>\n",
      "returncode: 0\n",
      "\n",
      "$ git add saved_artifacts/features_labels.pt saved_artifacts/sample_filenames.txt saved_artifacts/training_summary.csv\n",
      "=== STDOUT ===\n",
      "<none>\n",
      "=== STDERR ===\n",
      "fatal: pathspec 'saved_artifacts/features_labels.pt' did not match any files\n",
      "returncode: 128\n",
      "\n",
      "$ git commit -m \"Add extracted features, filename manifest, and summary\" || echo \"Nothing to commit\"\n",
      "=== STDOUT ===\n",
      "On branch main\n",
      "Your branch is up to date with 'origin/main'.\n",
      "\n",
      "Changes not staged for commit:\n",
      "  (use \"git add <file>...\" to update what will be committed)\n",
      "  (use \"git restore <file>...\" to discard changes in working directory)\n",
      "\tmodified:   CT-CLIP/CT_CLIP/ct_clip/__pycache__/__init__.cpython-39.pyc\n",
      "\tmodified:   CT-CLIP/CT_CLIP/ct_clip/__pycache__/ct_clip.cpython-39.pyc\n",
      "\tmodified:   CT-CLIP/CT_CLIP/ct_clip/__pycache__/mlm.cpython-39.pyc\n",
      "\tmodified:   CT-CLIP/CT_CLIP/ct_clip/__pycache__/visual_ssl.cpython-39.pyc\n",
      "\tmodified:   CT-CLIP/ct-clip.ipynb\n",
      "\tmodified:   CT-CLIP/transformer_maskgit/transformer_maskgit/__pycache__/MaskGITTransformer.cpython-39.pyc\n",
      "\tmodified:   CT-CLIP/transformer_maskgit/transformer_maskgit/__pycache__/__init__.cpython-39.pyc\n",
      "\tmodified:   CT-CLIP/transformer_maskgit/transformer_maskgit/__pycache__/attention.cpython-39.pyc\n",
      "\tmodified:   CT-CLIP/transformer_maskgit/transformer_maskgit/__pycache__/ctvit.cpython-39.pyc\n",
      "\tmodified:   CT-CLIP/transformer_maskgit/transformer_maskgit/__pycache__/ctvit_trainer.cpython-39.pyc\n",
      "\tmodified:   CT-CLIP/transformer_maskgit/transformer_maskgit/__pycache__/data.cpython-39.pyc\n",
      "\tmodified:   CT-CLIP/transformer_maskgit/transformer_maskgit/__pycache__/optimizer.cpython-39.pyc\n",
      "\tmodified:   CT-CLIP/transformer_maskgit/transformer_maskgit/__pycache__/t5.cpython-39.pyc\n",
      "\tmodified:   CT-CLIP/transformer_maskgit/transformer_maskgit/__pycache__/videotextdataset.cpython-39.pyc\n",
      "\n",
      "Untracked files:\n",
      "  (use \"git add <file>...\" to include in what will be committed)\n",
      "\tCT-CLIP/.ipynb_checkpoints/\n",
      "\n",
      "no changes added to commit (use \"git add\" and/or \"git commit -a\")\n",
      "Nothing to commit\n",
      "=== STDERR ===\n",
      "<none>\n",
      "returncode: 0\n",
      "\n",
      "$ git push origin main\n",
      "=== STDOUT ===\n",
      "<none>\n",
      "=== STDERR ===\n",
      "Everything up-to-date\n",
      "returncode: 0\n"
     ]
    }
   ],
   "source": [
    "import subprocess, os, textwrap\n",
    "\n",
    "def run(cmd):\n",
    "    print(f\"\\n$ {cmd}\")\n",
    "    proc = subprocess.run(cmd, shell=True, capture_output=True, text=True)\n",
    "    print(\"=== STDOUT ===\")\n",
    "    print(proc.stdout.strip() or \"<none>\")\n",
    "    print(\"=== STDERR ===\")\n",
    "    print(proc.stderr.strip() or \"<none>\")\n",
    "    print(f\"returncode: {proc.returncode}\")\n",
    "    return proc\n",
    "\n",
    "os.chdir(\"/data/ct-clip-app\")\n",
    "\n",
    "# Ensure identity\n",
    "run('git config user.name \"Mustafa Ak\"')\n",
    "run('git config user.email \"mustafaxacikgoz@gmail.com\"')\n",
    "\n",
    "# Show status\n",
    "run(\"git status\")\n",
    "\n",
    "# Stage artifacts\n",
    "run(\"git add saved_artifacts/features_labels.pt saved_artifacts/sample_filenames.txt saved_artifacts/training_summary.csv\")\n",
    "\n",
    "# Commit if needed\n",
    "run('git commit -m \"Add extracted features, filename manifest, and summary\" || echo \"Nothing to commit\"')\n",
    "\n",
    "# Push (with token if needed)\n",
    "# Try normal push first\n",
    "res = run(\"git push origin main\")\n",
    "if res.returncode != 0:\n",
    "    # Retry with embedded token from secret (adjust secret name if different)\n",
    "    token = os.environ.get(\"GITHUB_TOKEN\") or os.environ.get(\"hf_space_backup\")\n",
    "    if not token:\n",
    "        print(\"No GitHub token found in environment secrets; cannot retry authenticated push.\")\n",
    "    else:\n",
    "        run(f\"git remote set-url origin https://{token}@github.com/Mustafa-Acikgoz/ct-clip-app.git\")\n",
    "        run(\"git push origin main\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0391c64c-0657-423b-8deb-3a9d573d2e79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Installing system library libgl1-mesa-glx ---\n",
      "sudo: effective uid is not 0, is /usr/bin/sudo on a file system with the 'nosuid' option set or an NFS file system without root privileges?\n",
      "\n",
      "--- Installing Python packages ---\n",
      "\n",
      "--- Cloning GitHub repositories ---\n",
      "CT-CLIP repository already exists.\n",
      "\n",
      "--- Installing CT-CLIP subpackages in editable mode ---\n",
      "\u001b[33m  DEPRECATION: Legacy editable install of transformer-maskgit==0.0.0 from file:///data/ct-clip-app/CT-CLIP/transformer_maskgit (setup.py develop) is deprecated. pip 25.3 will enforce this behaviour change. A possible replacement is to add a pyproject.toml or enable --use-pep517, and use setuptools >= 64. If the resulting installation is not behaving as expected, try using --config-settings editable_mode=compat. Please consult the setuptools documentation for more information. Discussion can be found at https://github.com/pypa/pip/issues/11457\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "monai 1.5.0 requires torch<2.7.0,>=2.4.1, but you have torch 2.7.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[33m  DEPRECATION: Building 'ImageNetV2_pytorch' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'ImageNetV2_pytorch'. Discussion can be found at https://github.com/pypa/pip/issues/6334\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  DEPRECATION: Legacy editable install of ct-clip==0.1 from file:///data/ct-clip-app/CT-CLIP/CT_CLIP (setup.py develop) is deprecated. pip 25.3 will enforce this behaviour change. A possible replacement is to add a pyproject.toml or enable --use-pep517, and use setuptools >= 64. If the resulting installation is not behaving as expected, try using --config-settings editable_mode=compat. Please consult the setuptools documentation for more information. Discussion can be found at https://github.com/pypa/pip/issues/11457\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "==================================================\n",
      " âœ… Cell 1 complete.\n",
      " ðŸ”´ IMPORTANT: Please restart the kernel now before running Cell 2.\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# ==============================================================================\n",
    "# CELL 1: Environment and Dependencies Setup\n",
    "# ==============================================================================\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# --- 1. Install System Libraries ---\n",
    "print(\"--- Installing system library libgl1-mesa-glx ---\")\n",
    "!sudo apt-get update -qq && sudo apt-get install -y -qq libgl1-mesa-glx\n",
    "\n",
    "# --- 2. Install Python Packages ---\n",
    "print(\"\\n--- Installing Python packages ---\")\n",
    "!pip install -q --upgrade pip\n",
    "!pip install -q torch transformers datasets nibabel monai sentencepiece \\\n",
    "                einops vector-quantize-pytorch ema-pytorch beartype \\\n",
    "                opencv-python-headless protobuf huggingface_hub bitsandbytes pandas\n",
    "\n",
    "# --- 3. Clone CT-CLIP Repository ---\n",
    "print(\"\\n--- Cloning GitHub repositories ---\")\n",
    "if not os.path.isdir(\"CT-CLIP\"):\n",
    "    !git clone https://github.com/ibrahimethemhamamci/CT-CLIP.git -q\n",
    "    print(\"Cloned CT-CLIP.\")\n",
    "else:\n",
    "    print(\"CT-CLIP repository already exists.\")\n",
    "\n",
    "# --- 4. Install CT-CLIP Subpackages ---\n",
    "print(\"\\n--- Installing CT-CLIP subpackages in editable mode ---\")\n",
    "!pip install -q -e CT-CLIP/transformer_maskgit\n",
    "!pip install -q -e CT-CLIP/CT_CLIP\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\" âœ… Cell 1 complete.\")\n",
    "print(\" ðŸ”´ IMPORTANT: Please restart the kernel now before running Cell 2.\")\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e7dbae3-3763-4dd9-96c1-ad676c347807",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Using device: cuda ---\n",
      "\n",
      "--- Loading CT-CLIP Model ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "126d9ce2d91e4df5aec3bc7c99811d0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/659 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "924fa61f14624939917f9a37fa34d05f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "configuration_cxrbert.py:   0%|          | 0.00/889 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "115374111acc4000b2dc8c6d8bf1fd6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/235k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05cc0751f9424c6cb6cac70de030a7ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa4bd518302c4272affe6d71eb689af8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/843 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "817ea115658a43199c5b41d43e71ad4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modeling_cxrbert.py:   0%|          | 0.00/5.82k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11c24662c50b494c9c3a34c3061eb3b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/439M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading CT-CLIP v2 weights...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8696105a3f55478f9f3ca1b1c04cfd2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "models/CT-CLIP-Related/CT-CLIP_v2.pt:   0%|          | 0.00/1.77G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " âœ… CT-CLIP model loaded and frozen.\n",
      "\n",
      "--- Preparing labels ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bd3980fc42c4d8eb1963bf70732b618",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train_predicted_labels.csv:   0%|          | 0.00/2.76M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 18 classes.\n",
      "\n",
      "--- Extracting features for our mini-dataset ---\n",
      "Processing dataset/train/train_1001/train_1001_a/train_1001_a_1.nii.gz...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2e3c1bfc0344d1eb29bcecf1a5e6ede",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "dataset/train/train_1001/train_1001_a/tr(â€¦):   0%|          | 0.00/156M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/miniconda/lib/python3.9/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test all pooling\n",
      "Processing dataset/train/train_10047/train_10047_b/train_10047_b_2.nii.gz...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a7af359eae647088f4667f5f2162f38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "dataset/train/train_10047/train_10047_b/(â€¦):   0%|          | 0.00/223M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test all pooling\n",
      "Processing dataset/train/train_10080/train_10080_a/train_10080_a_1.nii.gz...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5aa3ef40005e4b128a4a86fac12cacac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "dataset/train/train_10080/train_10080_a/(â€¦):   0%|          | 0.00/410M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test all pooling\n",
      "Processing dataset/train/train_10098/train_10098_a/train_10098_a_1.nii.gz...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98615884cce343d199fa31e65f42b3c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "dataset/train/train_10098/train_10098_a/(â€¦):   0%|          | 0.00/109M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test all pooling\n",
      "Processing dataset/train/train_10128/train_10128_b/train_10128_b_2.nii.gz...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1abd5ff6bfd040de8f9c8a064565f398",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "dataset/train/train_10128/train_10128_b/(â€¦):   0%|          | 0.00/137M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test all pooling\n",
      "Processing dataset/train/train_10168/train_10168_a/train_10168_a_1.nii.gz...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f749cd54f7e41f7a2cf7ecb0c8b1c34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "dataset/train/train_10168/train_10168_a/(â€¦):   0%|          | 0.00/130M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test all pooling\n",
      "Processing dataset/train/train_1016/train_1016_a/train_1016_a_1.nii.gz...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ee50b1285c94c80b7542cdc86931919",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "dataset/train/train_1016/train_1016_a/tr(â€¦):   0%|          | 0.00/475M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cancellation requested; stopping current tasks.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda/lib/python3.9/site-packages/huggingface_hub/file_download.py:629\u001b[0m, in \u001b[0;36mxet_get\u001b[0;34m(incomplete_path, xet_file_data, headers, expected_size, displayed_filename, _tqdm_bar)\u001b[0m\n\u001b[1;32m    627\u001b[0m     progress\u001b[38;5;241m.\u001b[39mupdate(progress_bytes)\n\u001b[0;32m--> 629\u001b[0m \u001b[43mdownload_files\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    630\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxet_download_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[43m    \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconnection_info\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_info\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mconnection_info\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maccess_token\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconnection_info\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexpiration_unix_epoch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    633\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_refresher\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_refresher\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    634\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprogress_updater\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mprogress_updater\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    635\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 174\u001b[0m\n\u001b[1;32m    172\u001b[0m full_path \u001b[38;5;241m=\u001b[39m reconstruct_path_from_filename(filename)\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcessing \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfull_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 174\u001b[0m local_path \u001b[38;5;241m=\u001b[39m \u001b[43mhf_hub_download\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mibrahimhamamci/CT-RATE\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdataset\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfull_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mHF_TOKEN\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    180\u001b[0m ct_tensor \u001b[38;5;241m=\u001b[39m load_and_preprocess_ct(local_path)\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n",
      "File \u001b[0;32m~/miniconda/lib/python3.9/site-packages/huggingface_hub/utils/_validators.py:114\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_use_auth_token:\n\u001b[1;32m    112\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m--> 114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda/lib/python3.9/site-packages/huggingface_hub/file_download.py:1010\u001b[0m, in \u001b[0;36mhf_hub_download\u001b[0;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, user_agent, force_download, proxies, etag_timeout, token, local_files_only, headers, endpoint, resume_download, force_filename, local_dir_use_symlinks)\u001b[0m\n\u001b[1;32m    990\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _hf_hub_download_to_local_dir(\n\u001b[1;32m    991\u001b[0m         \u001b[38;5;66;03m# Destination\u001b[39;00m\n\u001b[1;32m    992\u001b[0m         local_dir\u001b[38;5;241m=\u001b[39mlocal_dir,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1007\u001b[0m         local_files_only\u001b[38;5;241m=\u001b[39mlocal_files_only,\n\u001b[1;32m   1008\u001b[0m     )\n\u001b[1;32m   1009\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1010\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_hf_hub_download_to_cache_dir\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1011\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Destination\u001b[39;49;00m\n\u001b[1;32m   1012\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1013\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# File info\u001b[39;49;00m\n\u001b[1;32m   1014\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1015\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1016\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1017\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1018\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# HTTP info\u001b[39;49;00m\n\u001b[1;32m   1019\u001b[0m \u001b[43m        \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1020\u001b[0m \u001b[43m        \u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1021\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhf_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1022\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1023\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1024\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Additional options\u001b[39;49;00m\n\u001b[1;32m   1025\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1026\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1027\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda/lib/python3.9/site-packages/huggingface_hub/file_download.py:1171\u001b[0m, in \u001b[0;36m_hf_hub_download_to_cache_dir\u001b[0;34m(cache_dir, repo_id, filename, repo_type, revision, endpoint, etag_timeout, headers, proxies, token, local_files_only, force_download)\u001b[0m\n\u001b[1;32m   1168\u001b[0m \u001b[38;5;66;03m# Local file doesn't exist or etag isn't a match => retrieve file from remote (or cache)\u001b[39;00m\n\u001b[1;32m   1170\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m WeakFileLock(lock_path):\n\u001b[0;32m-> 1171\u001b[0m     \u001b[43m_download_to_tmp_and_move\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1172\u001b[0m \u001b[43m        \u001b[49m\u001b[43mincomplete_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblob_path\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.incomplete\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1173\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdestination_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblob_path\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1174\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl_to_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl_to_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1175\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1176\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1177\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexpected_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexpected_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1178\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1179\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1180\u001b[0m \u001b[43m        \u001b[49m\u001b[43metag\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43metag\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1181\u001b[0m \u001b[43m        \u001b[49m\u001b[43mxet_file_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxet_file_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1182\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1183\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(pointer_path):\n\u001b[1;32m   1184\u001b[0m         _create_symlink(blob_path, pointer_path, new_blob\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/miniconda/lib/python3.9/site-packages/huggingface_hub/file_download.py:1723\u001b[0m, in \u001b[0;36m_download_to_tmp_and_move\u001b[0;34m(incomplete_path, destination_path, url_to_download, proxies, headers, expected_size, filename, force_download, etag, xet_file_data)\u001b[0m\n\u001b[1;32m   1721\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m xet_file_data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m is_xet_available():\n\u001b[1;32m   1722\u001b[0m     logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mXet Storage is enabled for this repo. Downloading file from Xet Storage..\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1723\u001b[0m     \u001b[43mxet_get\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1724\u001b[0m \u001b[43m        \u001b[49m\u001b[43mincomplete_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mincomplete_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1725\u001b[0m \u001b[43m        \u001b[49m\u001b[43mxet_file_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxet_file_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1726\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1727\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexpected_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexpected_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1728\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdisplayed_filename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1729\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1730\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1731\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m xet_file_data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m constants\u001b[38;5;241m.\u001b[39mHF_HUB_DISABLE_XET:\n",
      "File \u001b[0;32m~/miniconda/lib/python3.9/site-packages/huggingface_hub/file_download.py:629\u001b[0m, in \u001b[0;36mxet_get\u001b[0;34m(incomplete_path, xet_file_data, headers, expected_size, displayed_filename, _tqdm_bar)\u001b[0m\n\u001b[1;32m    626\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mprogress_updater\u001b[39m(progress_bytes: \u001b[38;5;28mfloat\u001b[39m):\n\u001b[1;32m    627\u001b[0m     progress\u001b[38;5;241m.\u001b[39mupdate(progress_bytes)\n\u001b[0;32m--> 629\u001b[0m \u001b[43mdownload_files\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    630\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxet_download_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[43m    \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconnection_info\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_info\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mconnection_info\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maccess_token\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconnection_info\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexpiration_unix_epoch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    633\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_refresher\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_refresher\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    634\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprogress_updater\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mprogress_updater\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    635\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# CELL 2: Data Preparation, Feature Extraction (204 Samples), and Saving\n",
    "# ==============================================================================\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import monai.transforms as T\n",
    "from huggingface_hub import hf_hub_download\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "# --- 0. Secure token access (no hardcoded tokens) ---\n",
    "HF_TOKEN = os.environ.get(\"HF_Token\")\n",
    "if not HF_TOKEN:\n",
    "    raise RuntimeError(\"HF_TOKEN missing from Secrets. Set it in Space Settings â†’ Secrets.\")\n",
    "\n",
    "# --- 1. Add cloned repos to Python path ---\n",
    "sys.path.insert(0, os.path.abspath(\"CT-CLIP/transformer_maskgit\"))\n",
    "sys.path.insert(0, os.path.abspath(\"CT-CLIP\"))\n",
    "from transformer_maskgit.MaskGITTransformer import CTViT\n",
    "from ct_clip.ct_clip import CTCLIP\n",
    "\n",
    "# --- 2. Configuration ---\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"--- Using device: {DEVICE} ---\")\n",
    "\n",
    "# --- 3. Load Pre-trained CT-CLIP Model ---\n",
    "print(\"\\n--- Loading CT-CLIP Model ---\")\n",
    "text_encoder_name = \"microsoft/BiomedVLP-CXR-BERT-specialized\"\n",
    "text_tokenizer_clip = AutoTokenizer.from_pretrained(text_encoder_name, trust_remote_code=True)\n",
    "text_encoder = AutoModel.from_pretrained(text_encoder_name, trust_remote_code=True)\n",
    "image_encoder = CTViT(dim=512, codebook_size=8192, image_size=480, patch_size=20,\n",
    "                     temporal_patch_size=10, spatial_depth=4, temporal_depth=4,\n",
    "                     dim_head=32, heads=8)\n",
    "vision_model = CTCLIP(image_encoder=image_encoder, text_encoder=text_encoder,\n",
    "                      dim_image=294912, dim_text=768, dim_latent=512).to(DEVICE)\n",
    "\n",
    "print(\"Downloading CT-CLIP v2 weights...\")\n",
    "ckpt_path = hf_hub_download(\n",
    "    repo_id=\"ibrahimhamamci/CT-RATE\",\n",
    "    repo_type=\"dataset\",\n",
    "    filename=\"models/CT-CLIP-Related/CT-CLIP_v2.pt\",\n",
    "    token=HF_TOKEN,\n",
    ")\n",
    "state = torch.load(ckpt_path, map_location=\"cpu\")\n",
    "vision_model.load_state_dict(state.get(\"state_dict\", state), strict=False)\n",
    "vision_model.eval()\n",
    "for param in vision_model.parameters():\n",
    "    param.requires_grad = False\n",
    "print(\" âœ… CT-CLIP model loaded and frozen.\")\n",
    "\n",
    "# --- 4. Prepare Labels and Data ---\n",
    "print(\"\\n--- Preparing labels ---\")\n",
    "labels_path = hf_hub_download(\n",
    "    repo_id=\"ibrahimhamamci/CT-RATE\",\n",
    "    repo_type=\"dataset\",\n",
    "    filename=\"dataset/multi_abnormality_labels/train_predicted_labels.csv\",\n",
    "    token=HF_TOKEN,\n",
    ")\n",
    "df_labels = pd.read_csv(labels_path)\n",
    "CLASS_NAMES = df_labels.columns[1:].tolist()\n",
    "print(f\"Found {len(CLASS_NAMES)} classes.\")\n",
    "\n",
    "# --- 5. Sample filenames (balanced 204) ---\n",
    "sample_filenames = [\n",
    "    \"train_1001_a_1.nii.gz\", \"train_10047_b_2.nii.gz\", \"train_10080_a_1.nii.gz\", \"train_10098_a_1.nii.gz\",\n",
    "    \"train_10128_b_2.nii.gz\", \"train_10168_a_1.nii.gz\", \"train_1016_a_1.nii.gz\", \"train_10172_a_1.nii.gz\",\n",
    "    \"train_10203_a_2.nii.gz\", \"train_10208_a_2.nii.gz\", \"train_10211_a_2.nii.gz\", \"train_10255_a_1.nii.gz\",\n",
    "    \"train_10432_d_2.nii.gz\", \"train_10516_a_1.nii.gz\", \"train_10633_a_2.nii.gz\", \"train_10641_h_1.nii.gz\",\n",
    "    \"train_1069_a_2.nii.gz\", \"train_10704_a_1.nii.gz\", \"train_10751_a_2.nii.gz\", \"train_10798_a_2.nii.gz\",\n",
    "    \"train_10805_a_1.nii.gz\", \"train_10822_a_2.nii.gz\", \"train_10858_a_2.nii.gz\", \"train_10872_a_1.nii.gz\",\n",
    "    \"train_10919_a_2.nii.gz\", \"train_10958_a_1.nii.gz\", \"train_10969_b_1.nii.gz\", \"train_11032_a_2.nii.gz\",\n",
    "    \"train_11103_a_1.nii.gz\", \"train_11111_d_1.nii.gz\", \"train_11124_a_1.nii.gz\", \"train_11175_a_3.nii.gz\",\n",
    "    \"train_11213_a_2.nii.gz\", \"train_11263_a_2.nii.gz\", \"train_11289_a_2.nii.gz\", \"train_11327_a_2.nii.gz\",\n",
    "    \"train_11331_a_1.nii.gz\", \"train_11334_a_2.nii.gz\", \"train_1138_a_2.nii.gz\", \"train_11418_b_2.nii.gz\",\n",
    "    \"train_11595_a_2.nii.gz\", \"train_11615_a_1.nii.gz\", \"train_11617_a_1.nii.gz\", \"train_1163_a_1.nii.gz\",\n",
    "    \"train_11649_a_1.nii.gz\", \"train_11687_a_1.nii.gz\", \"train_11687_a_2.nii.gz\", \"train_11779_a_1.nii.gz\",\n",
    "    \"train_11791_a_1.nii.gz\", \"train_11837_a_1.nii.gz\", \"train_11872_a_1.nii.gz\", \"train_11948_b_2.nii.gz\",\n",
    "    \"train_12005_b_2.nii.gz\", \"train_12012_a_2.nii.gz\", \"train_1207_a_1.nii.gz\", \"train_12094_a_2.nii.gz\",\n",
    "    \"train_12125_a_1.nii.gz\", \"train_12160_a_2.nii.gz\", \"train_12163_a_1.nii.gz\", \"train_12180_a_1.nii.gz\",\n",
    "    \"train_12195_a_2.nii.gz\", \"train_12265_a_1.nii.gz\", \"train_12283_a_2.nii.gz\", \"train_12357_a_2.nii.gz\",\n",
    "    \"train_12427_a_2.nii.gz\", \"train_12479_b_2.nii.gz\", \"train_12503_b_2.nii.gz\", \"train_12520_b_2.nii.gz\",\n",
    "    \"train_12522_a_2.nii.gz\", \"train_12537_c_1.nii.gz\", \"train_12542_a_1.nii.gz\", \"train_12572_a_1.nii.gz\",\n",
    "    \"train_12637_a_1.nii.gz\", \"train_12641_a_1.nii.gz\", \"train_12684_a_1.nii.gz\", \"train_12755_a_1.nii.gz\",\n",
    "    \"train_12794_c_2.nii.gz\", \"train_12850_a_1.nii.gz\", \"train_12863_b_1.nii.gz\", \"train_12875_a_1.nii.gz\",\n",
    "    \"train_12877_b_1.nii.gz\", \"train_12885_a_1.nii.gz\", \"train_12894_a_1.nii.gz\", \"train_12935_a_2.nii.gz\",\n",
    "    \"train_12952_a_1.nii.gz\", \"train_12971_a_1.nii.gz\", \"train_129_a_1.nii.gz\", \"train_13016_a_1.nii.gz\",\n",
    "    \"train_13176_b_1.nii.gz\", \"train_1320_a_2.nii.gz\", \"train_13216_a_1.nii.gz\", \"train_13224_a_2.nii.gz\",\n",
    "    \"train_13251_c_1.nii.gz\", \"train_13252_a_1.nii.gz\", \"train_13355_a_2.nii.gz\", \"train_13355_b_1.nii.gz\",\n",
    "    \"train_13368_b_2.nii.gz\", \"train_13393_a_1.nii.gz\", \"train_13420_a_1.nii.gz\", \"train_13437_d_1.nii.gz\",\n",
    "    \"train_13438_a_2.nii.gz\", \"train_13448_a_2.nii.gz\", \"train_13473_a_2.nii.gz\", \"train_1348_b_2.nii.gz\",\n",
    "    \"train_13592_a_2.nii.gz\", \"train_1378_c_1.nii.gz\", \"train_13829_a_2.nii.gz\", \"train_13844_a_2.nii.gz\",\n",
    "    \"train_13849_a_1.nii.gz\", \"train_13854_a_1.nii.gz\", \"train_13962_a_2.nii.gz\", \"train_14046_a_2.nii.gz\",\n",
    "    \"train_14058_b_2.nii.gz\", \"train_14098_a_1.nii.gz\", \"train_14122_a_1.nii.gz\", \"train_14166_d_1.nii.gz\",\n",
    "    \"train_14268_a_1.nii.gz\", \"train_14270_a_1.nii.gz\", \"train_14370_a_1.nii.gz\", \"train_14392_a_1.nii.gz\",\n",
    "    \"train_14442_h_2.nii.gz\", \"train_1448_c_1.nii.gz\", \"train_14552_a_1.nii.gz\", \"train_1455_a_1.nii.gz\",\n",
    "    \"train_14600_a_1.nii.gz\", \"train_14643_a_1.nii.gz\", \"train_14684_a_1.nii.gz\", \"train_14688_b_1.nii.gz\",\n",
    "    \"train_14690_a_2.nii.gz\", \"train_14701_b_2.nii.gz\", \"train_14709_a_1.nii.gz\", \"train_14740_b_2.nii.gz\",\n",
    "    \"train_14764_e_2.nii.gz\", \"train_14787_a_2.nii.gz\", \"train_14829_a_1.nii.gz\", \"train_14835_a_2.nii.gz\",\n",
    "    \"train_14909_a_2.nii.gz\", \"train_14920_a_2.nii.gz\", \"train_14940_a_2.nii.gz\", \"train_14952_a_2.nii.gz\",\n",
    "    \"train_15014_a_2.nii.gz\", \"train_15020_a_1.nii.gz\", \"train_15021_a_2.nii.gz\", \"train_1504_a_1.nii.gz\",\n",
    "    \"train_15057_a_1.nii.gz\", \"train_15062_a_1.nii.gz\", \"train_15076_b_1.nii.gz\", \"train_15076_b_2.nii.gz\",\n",
    "    \"train_1516_b_2.nii.gz\", \"train_15200_a_1.nii.gz\", \"train_15225_a_1.nii.gz\", \"train_15302_a_2.nii.gz\",\n",
    "    \"train_15338_a_2.nii.gz\", \"train_15357_a_1.nii.gz\", \"train_15445_a_1.nii.gz\", \"train_15485_a_1.nii.gz\",\n",
    "    \"train_15508_a_1.nii.gz\", \"train_15639_b_2.nii.gz\", \"train_15654_a_1.nii.gz\", \"train_15672_a_2.nii.gz\",\n",
    "    \"train_15673_a_2.nii.gz\", \"train_1569_a_1.nii.gz\", \"train_15748_a_2.nii.gz\", \"train_15767_a_1.nii.gz\",\n",
    "    \"train_15858_a_1.nii.gz\", \"train_15867_a_2.nii.gz\", \"train_15909_a_2.nii.gz\", \"train_15911_b_1.nii.gz\",\n",
    "    \"train_15911_b_2.nii.gz\", \"train_15918_a_1.nii.gz\", \"train_15956_b_1.nii.gz\", \"train_15957_a_2.nii.gz\",\n",
    "    \"train_16006_a_1.nii.gz\", \"train_1600_c_2.nii.gz\", \"train_16049_a_1.nii.gz\", \"train_16173_a_1.nii.gz\",\n",
    "    \"train_16173_a_2.nii.gz\", \"train_16176_b_1.nii.gz\", \"train_16215_a_1.nii.gz\", \"train_16223_a_2.nii.gz\",\n",
    "    \"train_16276_a_2.nii.gz\", \"train_16294_b_2.nii.gz\", \"train_1629_a_1.nii.gz\", \"train_16307_a_2.nii.gz\",\n",
    "    \"train_1630_a_1.nii.gz\", \"train_16379_a_1.nii.gz\", \"train_16447_a_1.nii.gz\", \"train_16485_a_2.nii.gz\",\n",
    "    \"train_16503_a_2.nii.gz\", \"train_16512_a_1.nii.gz\", \"train_16554_a_1.nii.gz\", \"train_16562_a_1.nii.gz\",\n",
    "    \"train_16566_b_1.nii.gz\", \"train_16602_a_1.nii.gz\", \"train_16621_a_2.nii.gz\", \"train_16627_a_2.nii.gz\",\n",
    "    \"train_16641_b_2.nii.gz\", \"train_16649_a_2.nii.gz\", \"train_16664_a_1.nii.gz\", \"train_16724_a_2.nii.gz\",\n",
    "    \"train_16775_a_1.nii.gz\", \"train_16779_a_2.nii.gz\", \"train_16815_b_1.nii.gz\", \"train_16819_a_1.nii.gz\",\n",
    "    \"train_16865_a_1.nii.gz\", \"train_16886_b_2.nii.gz\", \"train_16887_b_2.nii.gz\", \"train_16887_d_1.nii.gz\",\n",
    "    \"train_16893_a_2.nii.gz\", \"train_16928_a_2.nii.gz\", \"train_16961_a_1.nii.gz\", \"train_17013_a_2.nii.gz\",\n",
    "    \"train_17038_b_1.nii.gz\", \"train_1708_c_1.nii.gz\", \"train_17155_a_2.nii.gz\", \"train_171_b_2.nii.gz\",\n",
    "    \"train_17207_b_2.nii.gz\", \"train_17237_a_2.nii.gz\", \"train_17346_b_1.nii.gz\", \"train_17359_a_2.nii.gz\",\n",
    "    \"train_17379_a_1.nii.gz\", \"train_1742_c_1.nii.gz\", \"train_17459_a_1.nii.gz\", \"train_1746_a_1.nii.gz\",\n",
    "    \"train_17507_a_1.nii.gz\", \"train_17508_a_1.nii.gz\", \"train_17531_a_5.nii.gz\", \"train_17534_a_1.nii.gz\",\n",
    "    \"train_1753_e_2.nii.gz\", \"train_17553_a_1.nii.gz\", \"train_17610_a_1.nii.gz\", \"train_17634_b_1.nii.gz\",\n",
    "    \"train_17732_b_2.nii.gz\", \"train_17737_a_2.nii.gz\", \"train_17750_a_2.nii.gz\", \"train_17786_a_2.nii.gz\",\n",
    "    \"train_17828_a_2.nii.gz\", \"train_17835_a_2.nii.gz\", \"train_17877_a_1.nii.gz\", \"train_18010_a_2.nii.gz\",\n",
    "    \"train_18016_a_1.nii.gz\", \"train_18059_a_2.nii.gz\", \"train_18062_a_2.nii.gz\", \"train_18084_a_2.nii.gz\",\n",
    "    \"train_18119_a_1.nii.gz\", \"train_18130_b_2.nii.gz\", \"train_18136_a_2.nii.gz\", \"train_18207_b_2.nii.gz\",\n",
    "    \"train_18250_a_2.nii.gz\", \"train_18267_b_2.nii.gz\", \"train_18312_d_2.nii.gz\", \"train_18452_a_1.nii.gz\",\n",
    "    \"train_1845_a_5.nii.gz\", \"train_1845_b_1.nii.gz\", \"train_1845_c_2.nii.gz\", \"train_18465_b_2.nii.gz\",\n",
    "    \"train_18469_a_2.nii.gz\", \"train_18470_a_1.nii.gz\", \"train_1847_a_1.nii.gz\", \"train_18625_a_1.nii.gz\",\n",
    "    \"train_18663_a_2.nii.gz\", \"train_18668_a_2.nii.gz\", \"train_18678_a_2.nii.gz\", \"train_18744_a_1.nii.gz\",\n",
    "    \"train_18838_b_2.nii.gz\", \"train_18877_a_1.nii.gz\", \"train_18983_b_1.nii.gz\", \"train_19015_b_2.nii.gz\",\n",
    "    \"train_19041_a_2.nii.gz\", \"train_19061_a_1.nii.gz\", \"train_19070_a_1.nii.gz\", \"train_19088_d_2.nii.gz\",\n",
    "    \"train_19105_b_2.nii.gz\", \"train_19123_a_2.nii.gz\", \"train_19214_a_2.nii.gz\", \"train_19220_a_2.nii.gz\",\n",
    "    \"train_19230_a_1.nii.gz\", \"train_19244_c_1.nii.gz\", \"train_19263_a_2.nii.gz\", \"train_19269_a_2.nii.gz\",\n",
    "    \"train_19283_a_2.nii.gz\", \"train_19350_a_2.nii.gz\", \"train_19379_a_2.nii.gz\", \"train_19486_a_2.nii.gz\",\n",
    "    \"train_19512_a_2.nii.gz\", \"train_19551_a_1.nii.gz\", \"train_19578_a_2.nii.gz\", \"train_19640_a_1.nii.gz\",\n",
    "    \"train_19695_a_2.nii.gz\", \"train_19695_c_1.nii.gz\", \"train_19695_d_1.nii.gz\", \"train_1969_a_1.nii.gz\",\n",
    "    \"train_19819_a_2.nii.gz\", \"train_19844_a_2.nii.gz\", \"train_19845_a_2.nii.gz\", \"train_19874_a_2.nii.gz\",\n",
    "    \"train_19884_a_1.nii.gz\", \"train_19885_e_2.nii.gz\", \"train_19893_b_2.nii.gz\", \"train_1993_a_1.nii.gz\",\n",
    "    \"train_2002_a_1.nii.gz\", \"train_2107_a_2.nii.gz\", \"train_220_a_1.nii.gz\", \"train_2299_b_2.nii.gz\",\n",
    "    \"train_2410_d_2.nii.gz\", \"train_2423_a_2.nii.gz\", \"train_2650_a_2.nii.gz\", \"train_2755_a_1.nii.gz\",\n",
    "    \"train_2776_a_1.nii.gz\", \"train_2790_b_2.nii.gz\", \"train_2838_a_1.nii.gz\", \"train_2855_a_3.nii.gz\",\n",
    "    \"train_288_a_1.nii.gz\", \"train_2892_a_2.nii.gz\", \"train_2916_a_1.nii.gz\", \"train_3067_a_2.nii.gz\",\n",
    "    \"train_3089_a_2.nii.gz\", \"train_3113_a_2.nii.gz\", \"train_3114_a_3.nii.gz\", \"train_3138_a_2.nii.gz\",\n",
    "]\n",
    "\n",
    "# --- 6. Preprocessing and Feature Extraction ---\n",
    "def load_and_preprocess_ct(path: str):\n",
    "    transform = T.Compose([\n",
    "        T.LoadImaged(keys=[\"image\"]), T.EnsureChannelFirstd(keys=[\"image\"]),\n",
    "        T.ScaleIntensityRanged(keys=[\"image\"], a_min=-1000, a_max=1000,\n",
    "                               b_min=-1.0, b_max=1.0, clip=True),\n",
    "        T.Resized(keys=[\"image\"], spatial_size=(40, 480, 480),\n",
    "                  mode=\"trilinear\", align_corners=False),\n",
    "        T.ToTensord(keys=[\"image\"]),\n",
    "    ])\n",
    "    data = transform({\"image\": path})\n",
    "    return data[\"image\"].unsqueeze(0).to(DEVICE)\n",
    "\n",
    "def reconstruct_path_from_filename(filename: str) -> str:\n",
    "    parts = filename.replace('.nii.gz', '').split('_')\n",
    "    train_id = parts[1]\n",
    "    scan_id = parts[2]\n",
    "    return f\"dataset/train/train_{train_id}/train_{train_id}_{scan_id}/{filename}\"\n",
    "\n",
    "print(\"\\n--- Extracting features for our mini-dataset ---\")\n",
    "training_data = []\n",
    "for filename in sample_filenames:\n",
    "    try:\n",
    "        full_path = reconstruct_path_from_filename(filename)\n",
    "        print(f\"Processing {full_path}...\")\n",
    "        local_path = hf_hub_download(\n",
    "            repo_id=\"ibrahimhamamci/CT-RATE\",\n",
    "            repo_type=\"dataset\",\n",
    "            filename=full_path,\n",
    "            token=HF_TOKEN,\n",
    "        )\n",
    "        ct_tensor = load_and_preprocess_ct(local_path)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            dummy_text_input = text_tokenizer_clip([\"\"], return_tensors=\"pt\", padding=True).to(DEVICE)\n",
    "            _, image_embedding, _ = vision_model(dummy_text_input, ct_tensor, DEVICE, return_latents=True)\n",
    "\n",
    "        labels_row = df_labels[df_labels['VolumeName'] == filename]\n",
    "        if not labels_row.empty:\n",
    "            label_vector = torch.tensor(labels_row.iloc[0, 1:].values.astype(np.float32)).to(DEVICE)\n",
    "            training_data.append((image_embedding, label_vector))\n",
    "    except Exception as e:\n",
    "        print(f\"Could not process file {filename}. Error: {e}. Skipping.\")\n",
    "\n",
    "print(f\"\\n âœ… Cell 2 complete. Created a mini-dataset with {len(training_data)} samples.\")\n",
    "\n",
    "# === 7. Save extracted features and labels for later reuse ===\n",
    "os.makedirs(\"saved_artifacts\", exist_ok=True)\n",
    "image_embeddings = torch.cat([item[0] for item in training_data], dim=0)  # [N, 512]\n",
    "label_vectors = torch.stack([item[1] for item in training_data], dim=0)   # [N, num_classes]\n",
    "\n",
    "torch.save({\n",
    "    \"image_embeddings\": image_embeddings,\n",
    "    \"label_vectors\": label_vectors,\n",
    "    \"class_names\": CLASS_NAMES,\n",
    "}, \"saved_artifacts/features_labels.pt\")\n",
    "\n",
    "# Save sample filename manifest\n",
    "with open(\"saved_artifacts/sample_filenames.txt\", \"w\") as f:\n",
    "    for name in sample_filenames:\n",
    "        full_path = reconstruct_path_from_filename(name)\n",
    "        f.write(f\"{name}\\t{full_path}\\n\")\n",
    "\n",
    "# Save a human-readable summary\n",
    "summary_rows = []\n",
    "for i, (emb, label) in enumerate(training_data):\n",
    "    summary_rows.append({\n",
    "        \"sample_index\": i,\n",
    "        \"volume_name\": sample_filenames[i],\n",
    "        \"embedding_norm\": emb.norm().item(),\n",
    "        **{f\"class_{j}\": label[j].item() for j in range(label.shape[0])}\n",
    "    })\n",
    "df_summary = pd.DataFrame(summary_rows)\n",
    "df_summary.to_csv(\"saved_artifacts/training_summary.csv\", index=False)\n",
    "\n",
    "print(\"âœ… Saved features+labels, sample list, and summary to `saved_artifacts/`\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
